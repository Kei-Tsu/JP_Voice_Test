# ml_model.py
import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import streamlit as st

class VoiceFeatureExtractor:
    """éŸ³å£°ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def extract_features(self, audio_data, sr):
        """éŸ³å£°ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°"""
        features = {}
        
        # åŸºæœ¬çš„ãªéŸ³é‡ç‰¹å¾´é‡ï¼ˆRMSï¼‰
        rms = librosa.feature.rms(y=audio_data)[0]
        times = librosa.times_like(rms, sr=sr)
        features['rms'] = rms
        features['times'] = times
        features['mean_volume'] = np.mean(rms)
        features['std_volume'] = np.std(rms)
        features['max_volume'] = np.max(rms)
        features['min_volume'] = np.min(rms)
        
        # ä¼šè©±éŸ³å£°ã‚’ä¸‰åˆ†å‰²ã—ãŸåˆ†æ
        third = len(rms) // 3
        if third > 0:
            features['start_volume'] = np.mean(rms[:third])  # æœ€åˆã®1/3
            features['middle_volume'] = np.mean(rms[third:2*third])  # ä¸­é–“ã®1/3
            features['end_volume'] = np.mean(rms[2*third:])  # æœ€å¾Œã®1/3
        else:
            # éŸ³å£°ãŒçŸ­ã™ãã‚‹å ´åˆã¯å…¨ä½“ã®å¹³å‡ã‚’ä½¿ç”¨
            features['start_volume'] = features ['mean_volume']
            features['middle_volume'] = features ['mean_volume']
            features['end_volume'] = features ['mean_volume']

        # æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡ã®è¨ˆç®—
        features['end_drop_rate'] = (features['middle_volume'] - features['end_volume']) / features['middle_volume'] if features['middle_volume'] > 0 else 0
        
        # ã‚ˆã‚Šè©³ç´°ãªæ–‡æœ«åˆ†æï¼ˆæœ€å¾Œã®20%éƒ¨åˆ†ï¼‰
        end_portion = max(1, int(len(rms) * 0.2))  # æœ€å¾Œã®20%
        features['last_20_percent_volume'] = np.mean(rms[-end_portion:])
        features['last_20_percent_drop_rate'] = (features['mean_volume'] - features['last_20_percent_volume']) / features['mean_volume'] if features['mean_volume'] > 0 else 0
        
        # MFCCç‰¹å¾´é‡ï¼ˆéŸ³å£°ã®éŸ³è‰²ç‰¹æ€§ï¼‰
        try:
            mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
            for i in range(len(mfccs)):
                features[f'mfcc_{i+1}_mean'] = np.mean(mfccs[i])
                features[f'mfcc_{i+1}_std'] = np.std(mfccs[i])
        except Exception as e:
            # MFCCæŠ½å‡ºã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            for i in range(13):
                features[f'mfcc_{i+1}_mean'] = 0.0
                features[f'mfcc_{i+1}_std'] = 0.0

        # ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹æ€§
        try:
            spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sr)[0]
            features['spectral_centroid_mean'] = np.mean(spectral_centroid)
        except Exception as e:
            # ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹æ€§æŠ½å‡ºã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            features['spectral_centroid_mean'] = 0.0    
        
        # éŸ³å£°ã®ãƒšãƒ¼ã‚¹ï¼ˆã‚ªãƒ³ã‚»ãƒƒãƒˆæ¤œå‡ºã§éŸ³ç¯€ã‚’è¿‘ä¼¼ï¼‰
        try:
            onset_env = librosa.onset.onset_strength(y=audio_data, sr=sr)
            onsets = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)
            features['onset_count'] = len(onsets)
            features['speech_rate'] = len(onsets) / (len(audio_data) / sr) if len(audio_data) > 0 else 0
        except Exception as e:
            # ã‚ªãƒ³ã‚»ãƒƒãƒˆæ¤œå‡ºã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            features['onset_count'] = 0
            features['speech_rate'] = 0

        return features

    def extract_realtime_features(self, audio_segment):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã®è»½é‡ç‰¹å¾´é‡æŠ½å‡º"""
        try:
            # pydub AudioSegmentã‹ã‚‰numpyé…åˆ—ã«å¤‰æ›
            audio_data = np.array(audio_segment.get_array_of_samples(), dtype=np.float32)
            if audio_segment.channels == 2:
                audio_data = audio_data.reshape((-1, 2))
                audio_data = audio_data.mean(axis=1)  # ã‚¹ãƒ†ãƒ¬ã‚ªã‚’ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
            
            # æ­£è¦åŒ–
            if len(audio_data) > 0:
                audio_data = audio_data / (2**15)  # 16bitéŸ³å£°ã¨ã—ã¦æ­£è¦åŒ–
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
            sr = audio_segment.frame_rate
            
            # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã®ã¿æŠ½å‡ºï¼ˆå‡¦ç†é€Ÿåº¦å„ªå…ˆï¼‰
            features = {}
            
            # RMSéŸ³é‡
            if len(audio_data) > 0:
                rms = librosa.feature.rms(y=audio_data)[0]
                features['mean_volume'] = np.mean(rms)
                features['std_volume'] = np.std(rms)
                
                # ç°¡æ˜“çš„ãªæ–‡æœ«åˆ†æ
                third = len(rms) // 3
                if third > 0:
                    features['end_volume'] = np.mean(rms[2*third:])
                    features['middle_volume'] = np.mean(rms[third:2*third])
                    features['end_drop_rate'] = (features['middle_volume'] - features['end_volume']) / features['middle_volume'] if features['middle_volume'] > 0 else 0
                else:
                    features['end_volume'] = features['mean_volume']
                    features['middle_volume'] = features['mean_volume']
                    features['end_drop_rate'] = 0
            else:
                features['mean_volume'] = 0
                features['std_volume'] = 0
                features['end_volume'] = 0
                features['middle_volume'] = 0
                features['end_drop_rate'] = 0
            
            return features
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
            return {
                'mean_volume': 0,
                'std_volume': 0,
                'end_volume': 0,
                'middle_volume': 0,
                'end_drop_rate': 0
            }

def plot_audio_analysis(features, audio_data, sr):
    """éŸ³å£°åˆ†æã®è¦–è¦šåŒ–ã‚’è¡Œã†é–¢æ•°"""
    try:
        # 2ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
    
        # 1ã¤ç›®ã®ãƒ—ãƒ­ãƒƒãƒˆ: æ³¢å½¢è¡¨ç¤º
        librosa.display.waveshow(audio_data, sr=sr, ax=ax1)
        ax1.set_title('Audio Waveform')
        ax1.set_xlabel('Time (Seconds)')
        ax1.set_ylabel('Amplitude')
    
        # 2ã¤ç›®ã®ãƒ—ãƒ­ãƒƒãƒˆ: éŸ³é‡å¤‰åŒ–
        if 'rms' in features and 'times' in features:
            rms = features['rms']
            times = features['times']
            ax2.plot(times, rms, color='blue', label='Volume (RMS)')
            ax2.set_title('Volume Change Over Time')
            ax2.set_xlabel('Time (seconds)')
            ax2.set_ylabel('Volume (RMS)')
    
            # æ–‡æœ«éƒ¨åˆ†ï¼ˆæœ€å¾Œã®20%ï¼‰ã‚’å¼·èª¿è¡¨ç¤º
            if len(times) > 0:
                end_portion = max(1, int(len(times) * 0.2))  # æœ€å¾Œã®20%
                start_highlight = times[-end_portion]
                end_time = times[-1]
                ax2.axvspan(start_highlight, end_time, color='red', alpha=0.2)
                ax2.text(start_highlight + (end_time - start_highlight)/10, 
                        max(rms) * 0.8, 'End Part (last 20%)', color='red')
    
            # æ–‡é ­ãƒ»æ–‡ä¸­ãƒ»æ–‡æœ«ã®å¹³å‡éŸ³é‡ã‚’æ°´å¹³ç·šã§è¡¨ç¤º
            if 'start_volume' in features:
                ax2.axhline(y=features['start_volume'], color='green', linestyle='--', label='Start Volume Average')
            if 'middle_volume' in features:
                ax2.axhline(y=features['middle_volume'], color='orange', linestyle='--', label='Middle Volume Average')
            if 'end_volume' in features:
                ax2.axhline(y=features['end_volume'], color='red', linestyle='--', label='End Volume Average')
            ax2.legend()
        else:
            ax2.text(0.5, 0.5, 'éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“', fontsize=12, ha='center')
            ax2.set_title('Volume Change Over Time')

        plt.tight_layout()
        return fig
    except Exception as e:
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.text(0.5, 0.5, f'éŸ³å£°åˆ†æã‚¨ãƒ©ãƒ¼: {e}', fontsize=12, ha='center')
        ax.set_title('éŸ³å£°åˆ†æã‚¨ãƒ©ãƒ¼')
        ax.set_xlabel('éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')
        plt.tight_layout()
        return fig


def evaluate_clarity(features):
    """éŸ³é‡ç‰¹å¾´ã‹ã‚‰ã‚¯ãƒªã‚¢ãªç™ºè©±ã‹ã©ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹é–¢æ•°"""
    try:
        drop_rate = features.get("end_drop_rate", 0)
        last_20_drop_rate = features.get("last_20_percent_drop_rate", 0)  # ã‚­ãƒ¼ãŒãªã„å ´åˆã¯0

        # ä¸¡æ–¹ã®ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã‚’è€ƒæ…®ã—ãŸè©•ä¾¡
        avg_drop_rate = (drop_rate + last_20_drop_rate) / 2

        if avg_drop_rate < 0.1:
            clarity_level = "è‰¯å¥½"
            advice = "èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºè©±ã§ãã¦ã„ã¾ã™ï¼ãƒãƒ©ãƒ³ã‚¹ãŒã‚ˆã„ç™ºè©±ã§ã™ã€‚"
            score = min(100, int((1 - avg_drop_rate) * 100))
        elif avg_drop_rate < 0.25:
            clarity_level = "æ™®é€š"
            advice = "èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚å°‘ã—ã ã‘æ„è­˜ã‚’ã—ã¦è©±ã™ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚"
            score = int(75 - (avg_drop_rate - 0.1) * 100)
        elif avg_drop_rate < 0.4:
            clarity_level = "ã‚„ã‚„å¼±ã„"
            advice = "æ–‡æœ«ã®éŸ³é‡ãŒã‚„ã‚„å¼±ã‚ã§ã™ã€‚æ–‡æœ«ã‚’1éŸ³ä¸Šã’ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            score = int(60 - (avg_drop_rate - 0.25) * 100)
        else:
            clarity_level = "å°‘ã—é ‘å¼µã‚Šã¾ã—ã‚‡ã†"
            advice = "èªå°¾ã®éŸ³é‡ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚çµè«–ãŒæ­£ã—ãä¼ã‚ã‚‹ã‚ˆã†æ„è­˜ã—ã¦è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            score = max(20, int(40 - (avg_drop_rate - 0.4) * 50))
    
        return {
            "clarity_level": clarity_level,
            "advice": advice,
            "score": score,
            "avg_drop_rate": avg_drop_rate
        }
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        return {
            "clarity_level": "è©•ä¾¡ãŒã§ãã¾ã›ã‚“",
            "advice": "éŸ³å£°ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
            "score": 0,
            "avg_drop_rate": 0
        }   

# ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã«å¿œã˜ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
def get_feedback(drop_rate):
    """ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    try:
        if drop_rate < 0.1:
            return {
                "level": "good",
                "message": "è‰¯ã„æ„Ÿã˜ã§ã™ï¼èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºéŸ³ã§ãã¦ã„ã¾ã™ã€‚",
                "emoji": "ğŸŒŸ"
        }
        elif drop_rate < 0.25:
            return {
                "level": "medium",
                "message": "èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚å°‘ã—ã ã‘æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚",
                "emoji": "âš ï¸"
             }
        else:
            return {
                "level": "bad",
                "message": "èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’æ„è­˜ã—ã¦ï¼",
                "emoji": "â—"
            }
    except Exception as e:
        return {
            "level": "error",
            "message": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
            "emoji": "â“"
        }

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã®ãŸã‚ã®è£œåŠ©é–¢æ•°
def analyze_volume_realtime(audio_segment):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡åˆ†æ"""
    try:
        extractor = VoiceFeatureExtractor()
        features = extractor.extract_realtime_features(audio_segment)
        evaluation = evaluate_clarity(features)
        return features, evaluation
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        default_features = {
            'mean_volume': 0,
            'std_volume': 0,
            'end_volume': 0,
            'middle_volume': 0,
            'end_drop_rate': 0
        }
        default_evaluation = {
            'clarity_level': 'è©•ä¾¡ä¸å¯',
            'advice': 'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚',
            'score': 0,
            'avg_drop_rate': 0
        }
        return default_features, default_evaluation
