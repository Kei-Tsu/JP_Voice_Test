import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import librosa
import librosa.display
import tempfile
import os # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¿…è¦
import queue
import altair as alt # ã‚°ãƒ©ãƒ•æç”»ç”¨ 
import matplotlib.pyplot as plt # ã‚°ãƒ©ãƒ•æç”»ç”¨

# WebRTCé–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from streamlit_webrtc import webrtc_streamer, WebRtcMode # ãƒ–ãƒ©ã‚¦ã‚¶ã§éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from streamlit_webrtc import RTCConfiguration

import av
import scipy.io.wavfile
import time

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'volume_history' not in st.session_state:
    st.session_state.volume_history = []  # éŸ³é‡å±¥æ­´
if 'last_sound_time' not in st.session_state:
    st.session_state.last_sound_time = time.time()  # æœ€å¾Œã«éŸ³ãŒæ¤œå‡ºã•ã‚ŒãŸæ™‚é–“
if 'current_drop_rate' not in st.session_state:
    st.session_state.current_drop_rate = 0  # ç¾åœ¨ã®éŸ³é‡ä½ä¸‹ç‡
if 'end_of_sentence_detected' not in st.session_state:
    st.session_state.end_of_sentence_detected = False  # æ–‡æœ«æ¤œå‡ºãƒ•ãƒ©ã‚°
if 'feedback_history' not in st.session_state:
    st.session_state.feedback_history = []  # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´
if 'page' not in st.session_state:
    st.session_state.page = "ãƒ›ãƒ¼ãƒ "  # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
st.set_page_config(
    page_title="èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆã‚¢ãƒ—ãƒªã®è¦‹æ „ãˆã‚’ã‚ˆã‚Šã‚ˆã„ã‚‚ã®ã«ã™ã‚‹ãŸã‚ï¼‰
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 5px;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #F5F5F5;
        padding: 1rem;
        border-radius: 5px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    .feedback-box {
            padding: 1rem;
            border-radius: 5px;
            margin-top: 1rem;
            margin-bottom: 1rem;
    }
    .feedback-good {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
    }
    .feedback-medium {
        background-color: #FFF8E1;
        border-left: 5px solid #FFC107;
    }
    .feedback-bad {
        background-color: #FFEBEE;
        border-left: 5px solid #F44336;
    }
</style>
""", unsafe_allow_html=True)

# ä¼šè©±ã‚µãƒ³ãƒ—ãƒ«
CONVERSATION_SAMPLES = {
    "å®¶æ—ã¨ã®ä¼šè©±": [
        "ä»Šæ—¥ã®å¤•é£Ÿã€ãƒ‘ã‚¹ã‚¿ã«ã™ã‚‹ã­",
        "ã•ã£ãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹ãŸï¼Ÿãªã‚“ã‹é¢ç™½ã‹ã£ãŸã­",
        "æ˜¼é–“ã«ã€åŠ è—¤ã•ã‚“ãŒæ¥ãŸ",
        "åœŸæ›œæ—¥ã¯ä½•ã‹äºˆå®šã‚ã‚‹ï¼Ÿ1æ™‚ã«é›†åˆã­"
    ],
    "å‹äººã¨ã®ä¼šè©±": [
        "ã“ã®é–“ã®è©±ã®ç¶šããªã‚“ã ã‘ã©ã€çµå±€ã©ã†ãªã£ãŸã®ï¼Ÿ",
        "æ‹æ‰‹ã—ãŸã‚‰ã€æœ€å¾Œã«æ¡æ‰‹ã—ã¦ãã‚ŒãŸã‚ˆ",
        "æ–°ã—ã„ã‚«ãƒ•ã‚§è¦‹ã¤ã‘ãŸã‚“ã ã€‚ä»Šåº¦ä¸€ç·’ã«è¡Œã‹ãªã„ï¼Ÿ",
        "æœ€è¿‘ã©ã†ï¼Ÿä½•ã‹å¤‰ã‚ã£ãŸã“ã¨ã‚ã£ãŸï¼Ÿ"
    ],
    "æ‹äººã¨ã®ä¼šè©±": [
        "ã¡ã‚‡ã£ã¨ã“ã‚Œæ‰‹ä¼ã£ã¦ã‚‚ã‚‰ãˆã‚‹ï¼Ÿã™ãçµ‚ã‚ã‚‹ã‹ã‚‰",
        "çª“é–‹ã‘ã¦ã‚‚ã‚‰ã£ã¦ã‚‚ã„ã„ï¼Ÿã¡ã‚‡ã£ã¨æš‘ã„ã¨æ€ã£ã¦",
        "ã‚¿ã‚¯ã‚·ãƒ¼å‘¼ã‚“ã ã‘ã©ã€å‚ã®ä¸Šã«æ­¢ã¾ã£ã¦ã‚‹",
        "ã‚ã®ã­ã€æ˜¨æ—¥è¦‹ãŸæ˜ ç”»ãŒã™ã”ãè‰¯ã‹ã£ãŸã‚“ã "
    ]
}


# éŸ³å£°ç‰¹å¾´é‡æŠ½å‡ºã®ãŸã‚ã®é–¢æ•°
# éŸ³å£°åˆ†æã®ãŸã‚ã®ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã®å®šç¾©
class VoiceFeatureExtractor:
    """éŸ³å£°ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def extract_features(self, audio_data, sr):
        """éŸ³å£°ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°"""
        features = {}
        
        # åŸºæœ¬çš„ãªéŸ³é‡ç‰¹å¾´é‡ï¼ˆRMSï¼‰
        rms = librosa.feature.rms(y=audio_data)[0]
        times = librosa.times_like(rms, sr=sr)
        features['rms'] = rms
        features['times'] = times
        features['mean_volume'] = np.mean(rms)
        features['std_volume'] = np.std(rms)
        features['max_volume'] = np.max(rms)
        features['min_volume'] = np.min(rms)
        
        # ä¼šè©±éŸ³å£°ã‚’ä¸‰åˆ†å‰²ã—ãŸåˆ†æ
        third = len(rms) // 3
        features['start_volume'] = np.mean(rms[:third])  # æœ€åˆã®1/3
        features['middle_volume'] = np.mean(rms[third:2*third])  # ä¸­é–“ã®1/3
        features['end_volume'] = np.mean(rms[2*third:])  # æœ€å¾Œã®1/3
        
        # æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡ã®è¨ˆç®—
        features['end_drop_rate'] = (features['middle_volume'] - features['end_volume']) / features['middle_volume'] if features['middle_volume'] > 0 else 0
        
        # è¿½åŠ : ã‚ˆã‚Šè©³ç´°ãªæ–‡æœ«åˆ†æï¼ˆæœ€å¾Œã®20%éƒ¨åˆ†ï¼‰
        end_portion = max(1, int(len(rms) * 0.2))  # æœ€å¾Œã®20%
        features['last_20_percent_volume'] = np.mean(rms[-end_portion:])
        features['last_20_percent_drop_rate'] = (features['mean_volume'] - features['last_20_percent_volume']) / features['mean_volume'] if features['mean_volume'] > 0 else 0
        
        # è¿½åŠ : MFCCç‰¹å¾´é‡ï¼ˆéŸ³å£°ã®éŸ³è‰²ç‰¹æ€§ï¼‰
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
        for i in range(len(mfccs)):
            features[f'mfcc_{i+1}_mean'] = np.mean(mfccs[i])
            features[f'mfcc_{i+1}_std'] = np.std(mfccs[i])
        
        # è¿½åŠ : ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹æ€§
        spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sr)[0]
        features['spectral_centroid_mean'] = np.mean(spectral_centroid)
        
        # è¿½åŠ : éŸ³å£°ã®ãƒšãƒ¼ã‚¹ï¼ˆã‚ªãƒ³ã‚»ãƒƒãƒˆæ¤œå‡ºã§éŸ³ç¯€ã‚’è¿‘ä¼¼ï¼‰
        onset_env = librosa.onset.onset_strength(y=audio_data, sr=sr)
        onsets = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)
        features['onset_count'] = len(onsets)
        features['speech_rate'] = len(onsets) / (len(audio_data) / sr) if len(audio_data) > 0 else 0
        
        return features

def analyze_volume(y, sr):
    """åŸºæœ¬çš„ãªéŸ³é‡åˆ†æã‚’è¡Œã†é–¢æ•°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰"""
    extractor = VoiceFeatureExtractor()
    features = extractor.extract_features(y, sr)

def plot_audio_analysis(features, audio_data, sr):
    """éŸ³å£°åˆ†æã®è¦–è¦šåŒ–ã‚’è¡Œã†é–¢æ•°"""
    # 2ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
    
    # 1ã¤ç›®ã®ãƒ—ãƒ­ãƒƒãƒˆ: æ³¢å½¢è¡¨ç¤º
    librosa.display.waveshow(audio_data, sr=sr, ax=ax1)
    ax1.set_title('Audio Waveform')
    ax1.set_xlabel('Time (Seconds)')
    ax1.set_ylabel('Amplitude')
    
    # 2ã¤ç›®ã®ãƒ—ãƒ­ãƒƒãƒˆ: éŸ³é‡å¤‰åŒ–
    rms = features['rms']
    times = features['times']
    ax2.plot(times, rms, color='blue', label='Volume (RMS)')
    ax2.set_title('Volume Change Over Time')
    ax2.set_xlabel('Time (seconds)')
    ax2.set_ylabel('Volume (RMS)')
    
    # æ–‡æœ«éƒ¨åˆ†ï¼ˆæœ€å¾Œã®20%ï¼‰ã‚’å¼·èª¿è¡¨ç¤º
    if len(times) > 0:
        end_portion = max(1, int(len(times) * 0.2))  # æœ€å¾Œã®20%
        start_highlight = times[-end_portion]
        end_time = times[-1]
        ax2.axvspan(start_highlight, end_time, color='red', alpha=0.2)
        ax2.text(start_highlight + (end_time - start_highlight)/10, 
               max(rms) * 0.8, 'End Part (last 20%)', color='red')
    
    # æ–‡é ­ãƒ»æ–‡ä¸­ãƒ»æ–‡æœ«ã®å¹³å‡éŸ³é‡ã‚’æ°´å¹³ç·šã§è¡¨ç¤º
    ax2.axhline(y=features['start_volume'], color='green', linestyle='--', label='Start Volume Average')
    ax2.axhline(y=features['middle_volume'], color='orange', linestyle='--', label='Middle Volume Average')
    ax2.axhline(y=features['end_volume'], color='red', linestyle='--', label='End Volume Average')
    ax2.legend()
    
    plt.tight_layout()
    return fig

def evaluate_clarity(features):
    """éŸ³é‡ç‰¹å¾´ã‹ã‚‰ã‚¯ãƒªã‚¢ãªç™ºè©±ã‹ã©ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹é–¢æ•°"""
    drop_rate = features["end_drop_rate"]
    last_20_drop_rate = features.get("last_20_percent_drop_rate", 0)  # ã‚­ãƒ¼ãŒãªã„å ´åˆã¯0
    
    # ä¸¡æ–¹ã®ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã‚’è€ƒæ…®ã—ãŸè©•ä¾¡
    avg_drop_rate = (drop_rate + last_20_drop_rate) / 2
    
    if avg_drop_rate < 0.1:
        clarity_level = "è‰¯å¥½"
        advice = "èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºè©±ã§ãã¦ã„ã¾ã™ï¼ç´ æ™´ã‚‰ã—ã„ãƒãƒ©ãƒ³ã‚¹ã§ã™ã€‚"
        score = min(100, int((1 - avg_drop_rate) * 100))
    elif avg_drop_rate < 0.25:
        clarity_level = "æ™®é€š"
        advice = "èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ–‡æœ«ã‚’æ„è­˜ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚"
        score = int(75 - (avg_drop_rate - 0.1) * 100)
    elif avg_drop_rate < 0.4:
        clarity_level = "ã‚„ã‚„å¼±ã„"
        advice = "æ–‡æœ«ã®éŸ³é‡ãŒã‹ãªã‚Šä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’1éŸ³ä¸Šã’ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
        score = int(60 - (avg_drop_rate - 0.25) * 100)
    else:
        clarity_level = "æ”¹å–„å¿…è¦"
        advice = "èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ—¥æœ¬èªã¯æ–‡æœ«ã«é‡è¦ãªæƒ…å ±ã‚„çµè«–ãŒæ¥ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€æ–‡æœ«ã¾ã§æ„è­˜ã—ã¦ç›¸æ‰‹ã«ä¼ãˆã‚‹ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†ã€‚"
        score = max(20, int(40 - (avg_drop_rate - 0.4) * 50))
    
    return {
        "clarity_level": clarity_level,
        "advice": advice,
        "score": score,
        "avg_drop_rate": avg_drop_rate
    }

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
def audio_frame_callback(frame):
    """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    try:
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’numpyé…åˆ—ã«å¤‰æ›
        sound = frame.to_ndarray()
        
        # ç¾åœ¨ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        if len(sound) > 0:
            audio_data = sound.flatten()
            rms = np.sqrt(np.mean(audio_data**2))
            db = 20 * np.log10(max(rms, 1e-10))
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«éŸ³é‡å±¥æ­´ã‚’è¿½åŠ 
            st.session_state.volume_history.append({"éŸ³é‡": db})
            if len(st.session_state.volume_history) > 100:
                st.session_state.volume_history.pop(0)
            
            # æ–‡æœ«æ¤œå‡ºã®ãŸã‚ã®å‡¦ç†
            silence_threshold = -40  # ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ï¼ˆdBï¼‰
            
            # éŸ³é‡ãŒé–¾å€¤ã‚ˆã‚Šå¤§ãã„å ´åˆã€éŸ³å£°ã‚ã‚Š
            if db > silence_threshold:
                st.session_state.last_sound_time = time.time()
                st.session_state.end_of_sentence_detected = False
            else:
                # ç„¡éŸ³çŠ¶æ…‹ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸå ´åˆã€æ–‡æœ«ã¨åˆ¤æ–­
                current_time = time.time()
                silence_duration = (current_time - st.session_state.last_sound_time) * 1000  # ãƒŸãƒªç§’ã«å¤‰æ›
                
                if silence_duration > 500 and not st.session_state.end_of_sentence_detected:  # 0.5ç§’ä»¥ä¸Šã®ç„¡éŸ³
                    st.session_state.end_of_sentence_detected = True
                    
                    # æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ç‡ã‚’è¨ˆç®—
                    if len(st.session_state.volume_history) > 10:
                        recent_volumes = [item["éŸ³é‡"] for item in st.session_state.volume_history[-10:]]
                        
                        # ç°¡æ˜“çš„ãªæ–‡æœ«åˆ¤å®š
                        if len(recent_volumes) > 5:
                            before_avg = sum(recent_volumes[-7:-4]) / 3  # æ–‡æœ«å‰ã®å¹³å‡
                            after_avg = sum(recent_volumes[-3:]) / 3    # æ–‡æœ«ã®å¹³å‡
                            drop_rate = (before_avg - after_avg) / (abs(before_avg) + 1e-10)
                            
                            # åˆ¤å®šçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                            st.session_state.current_drop_rate = drop_rate
                            
                            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã«è¿½åŠ 
                            feedback = get_feedback(drop_rate)
                            st.session_state.feedback_history.append({
                                "time": time.strftime("%H:%M:%S"),
                                "drop_rate": drop_rate,
                                "feedback": feedback
                            })
    
    except Exception as e:
        print(f"éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    return frame

# ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã«å¿œã˜ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
def get_feedback(drop_rate):
    if drop_rate < 0.1:
        return {
            "level": "good",
            "message": "ç´ æ™´ã‚‰ã—ã„ï¼èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºéŸ³ã§ãã¦ã„ã¾ã™ã€‚",
            "emoji": "ğŸŒŸ"
        }
    elif drop_rate < 0.25:
        return {
            "level": "medium",
            "message": "èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚",
            "emoji": "âš ï¸"
        }
    else:
        return {
            "level": "bad",
            "message": "èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’æ„è­˜ã—ã¦ï¼",
            "emoji": "â—"
        }

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¡¨ç¤º
def display_volume_meter(placeholder):
    if len(st.session_state.volume_history) > 0:
        df = pd.DataFrame(st.session_state.volume_history)
        df = df.reset_index().rename(columns={"index": "æ™‚é–“"})
        
        chart = alt.Chart(df).mark_line().encode(
            x=alt.X("æ™‚é–“", axis=None),
            y=alt.Y("éŸ³é‡", title="éŸ³é‡ (dB)", scale=alt.Scale(domain=[-80, 0]))
        ).properties(
            height=200,
            width='container'
        )
        
        placeholder.altair_chart(chart, use_container_width=True)

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã®è¡¨ç¤º
def display_feedback_history(placeholder):
    if len(st.session_state.feedback_history) > 0:
        placeholder.subheader("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´")
        
        for i, feedback in enumerate(reversed(st.session_state.feedback_history[-5:])):  # æœ€æ–°5ä»¶ã®ã¿è¡¨ç¤º
            level = feedback["level"]
            css_class = f"feedback-box feedback-{level}"
            
            placeholder.markdown(
                f"<div class='{css_class}'>"
                f"<p>{feedback['time']} - {feedback['emoji']} {feedback['message']}</p>"
                f"<p>æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡: {feedback['drop_rate']:.2f}</p>"
                f"</div>",
                unsafe_allow_html=True
            )

# ã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†
def main():
    # ç‰¹å¾´æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
    feature_extractor = VoiceFeatureExtractor()
    
    # ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
    st.title('èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼')
    st.write('èº«è¿‘ãªä¼šè©±ã‚’ã—ã£ã‹ã‚Šä¼ãˆã‚‹ã“ã¨ã§ã€å¤§åˆ‡ãªäººã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã‚ˆã†')

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸é¸æŠ", ["ãƒ›ãƒ¼ãƒ ", "ç·´ç¿’ã‚’å§‹ã‚ã‚‹", "æœ¬ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦"])
    st.session_state.page = page  # ãƒšãƒ¼ã‚¸çŠ¶æ…‹ã‚’æ›´æ–°

    # ãƒšãƒ¼ã‚¸ã”ã¨ã®è¡¨ç¤ºå†…å®¹
    if page == "ãƒ›ãƒ¼ãƒ ":
        st.markdown('<h1 class="main-header">Welcomeï¼</h1>', unsafe_allow_html=True)
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.write("""
        ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®çŸ­ã„ä¼šè©±ã‚’åˆ†æã—ã€æ–‡æœ«ã®æ˜ç­ã•ã‚’é«˜ã‚ã‚‹ã“ã¨ã«æ³¨åŠ›ã—ã¦ã„ã¾ã™ã€‚
        æ—¥æœ¬èªã¯è¨€èªã®ç‰¹å¾´ä¸Šã€è‡ªç„¶ã¨èªå°¾ã®éŸ³å£°é‡ãŒä½ä¸‹ã—ãŒã¡ã§ã™ã€‚
        å®¶æ—ã‚„è¿‘ã—ã„äººã¨ã®ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªä¼šè©±ã‚„ã€å°å£°ã®ä¼šè©±ã§ç‰¹ã«ã“ã®å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚
        ä¸€æ–¹ã§æ„è­˜ã—ã™ãã¦å¤§ãã™ããŸã‚Šã€åŠ›ã‚’å…¥ã‚Œã™ãã‚‹ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãƒã‚¤ãƒŠã‚¹ã§ã™ã€‚
        ã‚ãªãŸã®ç™ºè©±ã‚’åˆ†æã—ã¦ã€è©±ã—æ–¹ã‚’é«˜ã‚ã‚‹ãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
        ãœã²ã€ã‚ãªãŸã®å£°ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚            
        
        ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ã‚ãªãŸã®ç™ºè©±ã‚’åˆ†æã—ã¦ã€èªå°¾ã®æ˜ç­ã•ã‚’è©•ä¾¡ã—ã€æ”¹å–„ã®ãŸã‚ã®ãƒ’ãƒ³ãƒˆã‚’
        æä¾›ã—ã¾ã™ã€‚2ã¤ã®æ–¹æ³•ã§ç·´ç¿’ã§ãã¾ã™ï¼š
        
        1. **éŒ²éŸ³æ¸ˆã¿ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**ã—ã¦è©³ç´°ãªåˆ†æã‚’å—ã‘ã‚‹
        2. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡**ã§ãƒã‚¤ã‚¯ã‹ã‚‰è©±ã—ãªãŒã‚‰å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾—ã‚‹
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
        st.markdown('<h2 class="sub-header">ä½¿ã„æ–¹</h2>', unsafe_allow_html=True)
        st.write("1. å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œç·´ç¿’ã‚’å§‹ã‚ã‚‹ã€ã‚’é¸æŠ")
        st.write("2. ç·´ç¿’ã—ãŸã„ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’é¸ã‚“ã§èª­ã¿ä¸Šã’ã‚‹")
        st.write("3. ã€ŒéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã¾ãŸã¯ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡ã€ã‚’é¸æŠ")
        st.write("4. åˆ†æçµæœã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç¢ºèª")
    
        if st.button("ç·´ç¿’ã‚’å§‹ã‚ã‚‹"):
            st.session_state.page = "ç·´ç¿’ã‚’å§‹ã‚ã‚‹"
            st.rerun() 

    elif page == "ç·´ç¿’ã‚’å§‹ã‚ã‚‹":
        st.markdown('<h1 class="sub-header">éŸ³å£°ç·´ç¿’</h1>', unsafe_allow_html=True)
    
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ã‚µãƒ³ãƒ—ãƒ«æ–‡ã®é¸æŠ
        category = st.selectbox("ä¼šè©±ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ", list(CONVERSATION_SAMPLES.keys()))
        sample_index = st.selectbox(
            "ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’é¸æŠ", 
            range(len(CONVERSATION_SAMPLES[category])),
            format_func=lambda i: CONVERSATION_SAMPLES[category][i]
        )
        
        selected_sample = CONVERSATION_SAMPLES[category][sample_index]
        
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.write("### èª­ã¿ä¸Šã’ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ–‡")
        st.write(selected_sample)
        st.write("ã“ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’ã€æ™®æ®µã®ã‚ˆã†ã«è‡ªç„¶ã«èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚")
        st.markdown('</div>', unsafe_allow_html=True)

        # ç·´ç¿’æ–¹æ³•ã®é¸æŠ
        practice_method = st.radio("ç·´ç¿’æ–¹æ³•ã‚’é¸æŠ", ["éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡"])

        if practice_method == "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ©Ÿèƒ½
            uploaded_file = st.file_uploader(
                "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", 
                type=["wav", "mp3"],
                key="file_uploader"
            )
            
            if uploaded_file is not None:
                try:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_file_path = tmp_file.name
                
                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿå¯èƒ½ã«è¡¨ç¤º
                    st.audio(tmp_file_path, format='audio/wav')    
                           
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                    y, sr = librosa.load(tmp_file_path, sr=None)
                
                    # éŸ³å£°ç‰¹å¾´é‡ã®æŠ½å‡º
                    features = feature_extractor.extract_features(y, sr)
                
                    # éŸ³å£°åˆ†æã®è¦–è¦šåŒ–
                    st.subheader("éŸ³å£°åˆ†æçµæœ")    
                    fig = plot_audio_analysis(features, y, sr)
                    st.pyplot(fig)
                
                    # éŸ³é‡åˆ†æçµæœã®è¡¨ç¤º
                    st.markdown('<h2 class="sub-header">éŸ³é‡åˆ†æçµæœ</h2>', unsafe_allow_html=True)
                        
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®è¡¨ç¤º
                        st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        st.metric("å¹³å‡éŸ³é‡", f"{features['mean_volume']:.4f}")
                        st.metric("æ–‡é ­éŸ³é‡", f"{features['start_volume']:.4f}")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.metric("æ–‡ä¸­éŸ³é‡", f"{features['middle_volume']:.4f}")
                        st.metric("æ–‡æœ«éŸ³é‡", f"{features['end_volume']:.4f}")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡", f"{features['end_drop_rate']:.4f}")
                        st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡(æœ€å¾Œã®20%)", f"{features['last_20_percent_drop_rate']:.4f}")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                    # éŸ³å£°æ˜ç­åº¦è©•ä¾¡
                    evaluation = evaluate_clarity(features)
                    
                    st.markdown('<h2 class="sub-header">éŸ³å£°æ˜ç­åº¦è©•ä¾¡</h2>', unsafe_allow_html=True)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        st.metric("æ˜ç­åº¦ã‚¹ã‚³ã‚¢", f"{evaluation['score']}/100")
                        st.metric("æ˜ç­åº¦è©•ä¾¡", evaluation['clarity_level'])
                        st.metric("ã‚¹ã‚³ã‚¢", f"{evaluation['score']}ç‚¹")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                    with col2:
                        st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        st.write("ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                        st.write(evaluation['advice'])
                        st.markdown('</div>', unsafe_allow_html=True)

                    # è©³ç´°ãªç‰¹å¾´é‡è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                    if st.checkbox("è©³ç´°ãªç‰¹å¾´é‡ã‚’è¡¨ç¤º"):
                        st.subheader("è©³ç´°ãªç‰¹å¾´é‡")
        
                    # ç‰¹å¾´é‡ã‚’ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«æ•´ç†ã—ã¦è¡¨ç¤º
                    # ãƒªã‚¹ãƒˆå‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã¾ãŸã¯å¤‰æ›
                    volume_features = {}
                    spectral_features = {}
                    rhythm_features = {}
        
                    # éŸ³é‡é–¢é€£ç‰¹å¾´é‡
                    for k, v in features.items():
                        if 'volume' in k or 'drop' in k:
                        # rmsã¨timesã¯é™¤å¤–ï¼ˆã“ã‚Œã‚‰ã¯ãƒªã‚¹ãƒˆå‹ã®ãŸã‚ï¼‰
                            if k not in ['rms', 'times'] and not isinstance(v, (list, np.ndarray)):
                                volume_features[k] = v
        
                    # ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡
                    for k, v in features.items():
                        if 'spectral' in k or 'mfcc' in k:
                            if not isinstance(v, (list, np.ndarray)):
                                spectral_features[k] = v
        
                    # ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡
                    for k, v in features.items():
                        if 'onset' in k or 'speech' in k:
                            if not isinstance(v, (list, np.ndarray)):
                                rhythm_features[k] = v
        
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ã¦è¡¨ç¤º
                    st.write("### éŸ³é‡é–¢é€£ç‰¹å¾´é‡")
                    if volume_features:
                        volume_df = pd.DataFrame({
                            'ç‰¹å¾´é‡': list(volume_features.keys()),
                            'å€¤': list(volume_features.values())
                        })
                        st.dataframe(volume_df)
                    else:
                        st.write("è¡¨ç¤ºã§ãã‚‹éŸ³é‡é–¢é€£ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
        
                    st.write("### ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡")
                    if spectral_features:
                        spectral_df = pd.DataFrame({
                            'ç‰¹å¾´é‡': list(spectral_features.keys()),
                            'å€¤': list(spectral_features.values())
                        })  
                        st.dataframe(spectral_df)
                    else:
                        st.write("è¡¨ç¤ºã§ãã‚‹ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
        
                    st.write("### ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡")
                    if rhythm_features:
                        rhythm_df = pd.DataFrame({
                            'ç‰¹å¾´é‡': list(rhythm_features.keys()),
                            'å€¤': list(rhythm_features.values())
                        })
                        st.dataframe(rhythm_df)
                    else:
                        st.write("è¡¨ç¤ºã§ãã‚‹ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")

                         
                    # ç·´ç¿’ã®ãƒ’ãƒ³ãƒˆã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
                    st.markdown('<h2 class="sub-header">ç·´ç¿’ã®ãƒ’ãƒ³ãƒˆ</h2>', unsafe_allow_html=True)
                    st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        
                    if evaluation["clarity_level"] in ["è‰¯å¥½"]:
                        st.write("ç´ æ™´ã‚‰ã—ã„ã§ã™ï¼èªå°¾ã¾ã§ç™ºè©±ã§ãã¦ã„ã¾ã™ã€‚")
                        st.write("- ã“ã®èª¿å­ã‚’ç¶­æŒã—ã¦ãã ã•ã„ï¼")
                        st.write("- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ä»–ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚„è‡ªç„¶ãªä¼šè©±ã§ã‚‚è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                    elif evaluation["clarity_level"] in ["æ™®é€š", "ã‚„ã‚„å¼±ã„"]:
                        st.write("- æ–‡ã®æœ€å¾Œã¾ã§æ¯ã‚’æ®‹ã™ã‚ˆã†ã«æ„è­˜ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                        st.write("- ä¾‹ãˆã°ã€æ–‡æœ«ã¾ã§æ„è­˜ã—ã¦è©±ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
                        st.write("- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: æ¯ã‚’å¸ã†ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ„è­˜ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                    else:
                        st.write("- æ–‡æœ«ã‚’æ„è­˜ã—ã¦ã€æ–‡ã‚’è©±ã—å§‹ã‚ã‚‹å‰ã«æ¯ã‚’å¸ã£ã¦ã‹ã‚‰è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                        st.write("- ä¾‹ãˆã°ã€æ–‡æœ«ã‚’1éŸ³ä¸Šã’ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                        st.write("- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: éŒ²éŸ³ã—ã¦ã”è‡ªèº«ã®å£°ã‚’è´ãã“ã¨ã§ã€è©±ã—æ–¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚")
                        
                    st.markdown('</div>', unsafe_allow_html=True)
                        
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.remove(tmp_file_path)
                    st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        
                except Exception as e:
                    error_msg =str(e)
                    if "PySoundFile" in error_msg:
                        st.error("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚åˆ¥ã®wavã¾ãŸã¯mp3å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
                    elif "empty_file" in error_msg:
                        st.error("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒã„ã‚‹ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™ã€‚æœ‰åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                    else:
                        st.error(f"éŸ³å£°åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    try:
                        os.unlink(tmp_file_path)
                    except:
                        pass

        elif practice_method == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡":
            st.write("### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡")
            st.info("ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ãƒã‚¤ã‚¯ä½¿ç”¨è¨±å¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ‰¿èªã—ã¦ãã ã•ã„ã€‚ãã®å¾Œã€ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’èª­ã¿ä¸Šã’ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è©•ä¾¡ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                    
            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®æº–å‚™ï¼ˆå‹•çš„æ›´æ–°ç”¨ï¼‰
            status_placeholder = st.empty()
            volume_placeholder = st.empty()
            feedback_placeholder = st.empty()
            history_placeholder = st.empty()
            recording_status_placeholder = st.empty()
            analysis_placeholder = st.empty()

            try:
                # WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’è¨­å®š
                webrtc_ctx = webrtc_streamer(
                    key="speech-evaluation",
                    mode=WebRtcMode.SENDONLY,
                    audio_frame_callback=audio_frame_callback,
                    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
                    media_stream_constraints={"video": False, "audio": True}
                )
                
                # WebRTCæ¥ç¶šãŒæœ‰åŠ¹ãªå ´åˆ
                if webrtc_ctx.state.playing:
                    # éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¡¨ç¤º
                    display_volume_meter(volume_placeholder)
                            
                    # çŠ¶æ…‹è¡¨ç¤º
                    if st.session_state.end_of_sentence_detected:
                        drop_rate = st.session_state.current_drop_rate
                                
                        if drop_rate < 0.1:
                            status_placeholder.success("- ç´ æ™´ã‚‰ã—ã„ã§ã™ï¼èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºéŸ³ã§ãã¦ã„ã¾ã™ã€‚")
                        elif drop_rate < 0.25:
                            status_placeholder.info("- èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚")
                        else:
                            status_placeholder.warning("- èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’æ„è­˜ã—ã¦ï¼")
                    else:
                        status_placeholder.info("- ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚æ–‡æœ«ã‚’æ¤œå‡ºã—ãŸã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                            
                    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã®è¡¨ç¤º
                    display_feedback_history(feedback_placeholder)

                    # ä½¿ã„æ–¹ã®è£œè¶³
                    with history_placeholder.expander("è©³ã—ã„ä½¿ã„æ–¹"):
                        st.write("""
                        1. ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’è‡ªç„¶ãªå£°ã§èª­ã¿ä¸Šã’ã¦ãã ã•ã„
                        2. ä¸€åº¦ã«1ã¤ã®æ–‡ã‚’èª­ã¿ã€é–“ã‚’ç©ºã‘ã¾ã—ã‚‡ã†
                        3. æ–‡ã®çµ‚ã‚ã‚Šã§å°‘ã—é–“ã‚’ç©ºã‘ã‚‹ã¨ã€æ–‡æœ«ã¨åˆ¤æ–­ã•ã‚Œãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
                        4. è¤‡æ•°ã®æ–‡ã‚’èª­ã‚“ã§ç·´ç¿’ã‚’ç¶šã‘ã‚‹ã¨ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
                        5. éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§è‡ªåˆ†ã®å£°ã®å¤§ãã•ã‚’ç¢ºèªã§ãã¾ã™
                        """)
                                
                        st.write("### éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®ç›®å®‰")
                        st.write("- -20dBä»¥ä¸Š: ã‹ãªã‚Šå¤§ããªå£°")
                        st.write("- -30dBï½-20dB: é€šå¸¸ã®ä¼šè©±éŸ³é‡")
                        st.write("- -40dBï½-30dB: å°å£°")
                        st.write("- -40dBä»¥ä¸‹: ç„¡éŸ³ã¾ãŸã¯éå¸¸ã«å°ã•ã„éŸ³")
                else:
                    status_placeholder.warning("ãƒã‚¤ã‚¯æ¥ç¶šå¾…æ©Ÿä¸­...ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
            
            except Exception as e:
                st.error(f"ãƒã‚¤ã‚¯æ©Ÿèƒ½ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.info("ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ãŒWebRTCã«å¯¾å¿œã—ã¦ã„ãªã„ã‹ã€ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    elif page == "æœ¬ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦":
        st.markdown('<h1 class="sub-header">ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦</h1>', unsafe_allow_html=True)
            
        st.write("""
        ## èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼
            
        ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸéŸ³å£°åˆ†æã‚¢ãƒ—ãƒªã§ã™ã€‚ç‰¹ã«æ—¥æœ¬èªã®æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ã®å‚¾å‘ã‚’æ¤œå‡ºã—ã€ã‚ˆã‚Šæ˜ç¢ºãªç™ºè©±ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
            
        ### é–‹ç™ºèƒŒæ™¯
            
        æ—¥æœ¬èªã¯SOVå‹ã®è¨€èªã§ã‚ã‚Šã€æ–‡æœ«ã«è¿°èªã‚„é‡è¦ãªæƒ…å ±ãŒé›†ä¸­ã—ã¾ã™ã€‚ã—ã‹ã—ç™ºè©±ä¸­ã¯æ™‚é–“ã®çµŒéã¨ã¨ã‚‚ã«è‚ºã®ç©ºæ°—ãŒæ¸›å°‘ã—ã€æ–‡æœ«ã§ã¯è‡ªç„¶ã¨å£°é‡ãŒä½ä¸‹ã—ã¾ã™ã€‚ç‰¹ã«å®¶æ—ã‚„å‹äººã¨ã®è¦ªå¯†ãªä¼šè©±ã§ã¯æ°—ãŒç·©ã¿ã€ã“ã®å‚¾å‘ãŒå¼·ããªã‚Šã¾ã™ã€‚
            
               
        ### æ—¥æœ¬èªã®SOVæ§‹é€ ã¨éŸ³é‡ä½ä¸‹
            
        æ—¥æœ¬èªã®ã‚ˆã†ãªSOVæ§‹é€ ï¼ˆSubject-Object-Verbã€ä¸»èª-ç›®çš„èª-å‹•è©ï¼‰ã®è¨€èªã§ã¯ã€æ–‡æœ«ã«å‹•è©ã‚„é‡è¦ãªæƒ…å ±ãŒæ¥ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ä¾‹ãˆã°ï¼š
            
        - ã€Œç§ã¯**ãƒªãƒ³ã‚´ã‚’é£Ÿã¹ã¾ã™**ã€ï¼ˆæ—¥æœ¬èªï¼šSOVï¼‰
        - "I eat an apple"ï¼ˆè‹±èªï¼šSVOï¼‰
            
        è‹±èªã§ã¯ç›®çš„èªï¼ˆappleï¼‰ãŒæ–‡æœ«ã«ã‚ã‚Šã¾ã™ãŒã€æ—¥æœ¬èªã§ã¯å‹•è©ï¼ˆé£Ÿã¹ã¾ã™ï¼‰ãŒæ–‡æœ«ã«æ¥ã¾ã™ã€‚ã“ã®ãŸã‚ã€æ—¥æœ¬èªã§ã¯æ–‡æœ«ã®æ˜ç­ã•ãŒã‚ˆã‚Šé‡è¦ã«ãªã‚Šã¾ã™ã€‚
            
        ### ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½
            
        - éŸ³å£°æ³¢å½¢ã¨éŸ³é‡å¤‰åŒ–ã®å¯è¦–åŒ–
        - æ–‡æœ«éŸ³é‡ä½ä¸‹ã®æ¤œå‡ºã¨è©•ä¾¡
        - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®æä¾›
        - è©³ç´°ãªéŸ³å£°ç‰¹å¾´é‡ã®åˆ†æ
        - ç·´ç¿’ã®ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã®æä¾›
            
        ### ä½¿ç”¨æŠ€è¡“
            
        - Python
        - Streamlit
        - librosaï¼ˆéŸ³å£°å‡¦ç†ï¼‰
        - WebRTCï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ï¼‰
        - æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆç‰¹å¾´é‡åˆ†æï¼‰
            
        ### å‚è€ƒæ–‡çŒ®
            
        - Chasin M. Sentence final hearing aid gain requirements of some non-English languages. Can J Speech-Lang Pathol Audiol. 2012;36(3):196-203.
        - æ—¥æœ¬èªæ—¥å¸¸ä¼šè©±ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰è¦‹ãˆã‚‹ä¼šè©±å ´é¢ã¨å£°ã®é«˜ã•ã®é–¢ä¿‚æ€§ (https://repository.ninjal.ac.jp/records/3193)
        - å°å£°ã¨ã¯ä½•ã‹ã€ã¾ãŸã¯è¨€èªã®é•ã„ãŒå°å£°ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã®ã‹ (https://www.oticon.co.jp/hearing-aid-users/blog/2020/20200512)
        """)
            
        st.write("### ç•™æ„äº‹é …")
        st.info("""
        - æœ¬ã‚¢ãƒ—ãƒªã¯ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ãŸã‚ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é…æ…®ã—ã¦ãã ã•ã„
        - éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ã«ä¿å­˜ã•ã‚Œã€åˆ†æå¾Œã«å‰Šé™¤ã•ã‚Œã¾ã™
        - æœ¬ã‚¢ãƒ—ãƒªã¯ã€ä¸€èˆ¬çš„ãªéŸ³å£°åˆ†æã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€ç‰¹å®šã®å€‹äººã‚„çŠ¶æ³ã«å¯¾ã™ã‚‹è©•ä¾¡ã‚’è¡Œã†ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“
        - æœ¬ã‚¢ãƒ—ãƒªã¯ã€å°‚é–€çš„ãªéŸ³å£°åˆ†æãƒ„ãƒ¼ãƒ«ã§ã¯ãªãã€ã‚ãã¾ã§å‚è€ƒã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„
        """)

# ã‚¢ãƒ—ãƒªã®å®Ÿè¡Œ
if __name__ == "__main__":
    main()
    print("ã‚¢ãƒ—ãƒªãŒèµ·å‹•ã•ã‚Œã¾ã—ãŸ")