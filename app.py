import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import librosa
import librosa.display
import tempfile
import os # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¿…è¦
import queue
import altair as alt # ã‚°ãƒ©ãƒ•æç”»ç”¨ 
import matplotlib.pyplot as plt # ã‚°ãƒ©ãƒ•æç”»ç”¨

# WebRTCé–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from streamlit_webrtc import webrtc_streamer, WebRtcMode # ãƒ–ãƒ©ã‚¦ã‚¶ã§éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from streamlit_webrtc import RTCConfiguration

RTC_CONFIGURATION = {
    "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
}

import av
import scipy.io.wavfile
import time

def get_file_extension(filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’å®‰å…¨ã«å–å¾—ã™ã‚‹é–¢æ•°"""
    filename = filename.lower()
    if filename.endswith(".wav"):
        return ".wav"
    elif filename.endswith(".mp3"):
        return ".mp3"
    else:
        return None

def is_audio_file(filename):
    """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°"""
    ext = get_file_extension(filename)
    return ext in [".wav", ".mp3"]

# å¤‰æ•°ã‚’åˆæœŸåŒ–
uploaded_file = None  # å¤‰æ•°ã‚’äº‹å‰ã«å®šç¾©ã™ã‚‹

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'recording_state' not in st.session_state:
    st.session_state.recording_state = {"is_recording": False} # éŒ²éŸ³ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
if 'recorded_frames' not in st.session_state:
    st.session_state.recorded_frames = [] # éŒ²éŸ³ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
if 'recorded_audio' not in st.session_state:
    st.session_state.recorded_audio_path = None # éŒ²éŸ³ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
if 'volume_history' not in st.session_state:
    st.session_state.volume_history = []  # éŸ³é‡å±¥æ­´ï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ï¼‰
if 'last_sound_time' not in st.session_state:
    st.session_state.last_sound_time = time.time()  # æœ€å¾Œã«éŸ³ãŒæ¤œå‡ºã•ã‚ŒãŸæ™‚é–“
if 'silence_threshold' not in st.session_state:
    st.session_state.silence_threshold = -35  # ç„¡éŸ³ã¨åˆ¤å®šã™ã‚‹dBã®ã—ãã„å€¤
if 'auto_stop_duration' not in st.session_state:
    st.session_state.auto_stop_duration = 1000  # è‡ªå‹•åœæ­¢ã™ã‚‹ç„¡éŸ³æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
if "input_method" not in st.session_state:
    st.session_state.input_method = "éŒ²éŸ³ã™ã‚‹"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å…¥åŠ›æ–¹æ³•  

def start_recording():
    """éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°"""
    st.session_state.recording_state["is_recording"] = True
    st.session_state.recorded_frames = []  # éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¯ãƒªã‚¢
    st.toast("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ", icon="ğŸ¤")
    
def stop_recording():
    """éŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹é–¢æ•°"""
    st.session_state.recording_state["is_recording"] = False
    st.toast("éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ", icon="âœ…")
    # éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã¯å‡¦ç†
    if len(st.session_state.recorded_frames) > 0:
        return True
    return False

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼ˆWebRTCã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
global_recording_state = {"is_recording": False}
global_recorded_frames = []

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ç”¨ã®ã‚­ãƒ¥ãƒ¼
audio_queue = queue.Queue()
# recorded_frames = []
# recording_state = {"is_recording": False}

# éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
def audio_frame_callback(frame):
    """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    
    try:
        sound = frame.to_ndarray()

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«éŒ²éŸ³çŠ¶æ…‹ã®ç¢ºèª
        if global_recording_state["is_recording"]:
            # éŒ²éŸ³ä¸­ã®å ´åˆã®ã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜
            global_recorded_frames.append(sound.copy())
            
    except Exception as e:
        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    return frame
          
    # ç¾åœ¨ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
    audio_data = sound.flatten() 
    if len(audio_data) > 0:
        # RMS(äºŒä¹—å¹³å‡å¹³æ–¹æ ¹ï¼‰ã§éŸ³é‡ã‚’è¨ˆç®—
        rms = np.sqrt(np.mean(audio_data**2))  # RMSéŸ³é‡è¨ˆç®—
        db = 20 * np.log10(max(rms, 1e-10))  # dBã«å¤‰æ›(éå¸¸ã«å°ã•ã„å€¤ã®å ´åˆã®å¯¾ç­–)

        # éŸ³é‡å±¥æ­´ã«è¿½åŠ ï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ï¼‰
        if 'volume_history' in st.session_state:
            st.session_state.volume_history.append({"éŸ³é‡": db})
            # éŸ³é‡å±¥æ­´ã®é•·ã•ã‚’åˆ¶é™(ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚)
                     

        # éŒ²éŸ³ä¸­ã®å ´åˆã®ã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜ï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¸›ã‚‰ã™ãŸã‚ï¼‰
        if st.session_state.recording_state ["is_recording"]:
            st.session_state.recorded_frames.append(sound.copy())  # éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜

def audio_frame_callback(frame):
    """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    try:
        sound = frame.to_ndarray()
    except Exception as e:
        st.error(f"Error processing audio frame: {e}")
        return frame

def show_debug_info(webrtc_ctx):
    """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°"""   
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤ºã‚ªãƒ³/ã‚ªãƒ•ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ãŸã‚ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
    if st.checkbox("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º", value=False):
        st.write("### ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        st.write(f"WebRTCã®çŠ¶æ…‹: {webrtc_ctx.state}")
        st.write(f"éŒ²éŸ³çŠ¶æ…‹: {st.session_state.recording_state}")
        st.write(f"éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(st.session_state.recorded_frames)}")

        # è¿½åŠ ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if 'current_silence_duration' in st.session_state:
            st.write(f"ç¾åœ¨ã®ç„¡éŸ³æ™‚é–“: {st.session_state.current_silence_duration:.2f} ms")

        if 'volume_history' in st.session_state:
            st.write(f"éŸ³é‡å±¥æ­´ãƒ‡ãƒ¼ã‚¿æ•°: {len(st.session_state.volume_history)}")

        # æœ€æ–°ã®éŸ³é‡ã‚’è¡¨ç¤º
        if 'volume_history' in st.session_state and len(st.session_state.volume_history) > 0:
            st.write(f"æœ€æ–°ã®éŸ³é‡å±¥æ­´: {st.session_state.volume_history[-1]['éŸ³é‡']:.2f} dB")
            
# éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼è¡¨ç¤ºç”¨ã®é–¢æ•°
def display_volume_meter(placeholder):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°"""
    if 'volume_history' in st.session_state and len(st.session_state.volume_history) > 0:
        # éŸ³é‡å±¥æ­´ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
        df = pd.DataFrame(st.session_state.volume_history)
        df = df.reset_index().rename(columns={"index": "æ™‚é–“"})

        # Altairã‚’ä½¿ã£ãŸã‚°ãƒ©ãƒ•è¡¨ç¤º
        chart = alt.Chart(df).mark_line().encode(
            x=alt.X("æ™‚é–“", axis=None),  # xè»¸ãƒ©ãƒ™ãƒ«ã‚’éè¡¨ç¤º
            y=alt.Y("éŸ³é‡", title="éŸ³é‡ (dB)", scale=alt.Scale(domain=[-80, 0]))
        ).properties(
            height=200,
            width='container'
        )

        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
        placeholder.altair_chart(chart, use_container_width=True)

def recording_controls(webrtc_ctx, status_placeholder, recording_status_placeholder):
    """éŒ²éŸ³æ“ä½œã®UIéƒ¨åˆ†"""
    if webrtc_ctx.state.playing:
        # WebRTCæ¥ç¶šãŒæœ‰åŠ¹ãªå ´åˆ
        status_placeholder.success("ãƒã‚¤ã‚¯ãŒæ¥ç¶šã•ã‚Œã¦ã„ã¾ã™", icon="âœ…")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ï¼ˆéŒ²éŸ³ä¸­ã¯ç„¡åŠ¹åŒ–ï¼‰
            start_button = st.button(
                "éŒ²éŸ³é–‹å§‹", 
                disabled=st.session_state.recording_state["is_recording"],
                key="start_rec_button"
            )
            if start_button:
                # éŒ²éŸ³é–‹å§‹å‡¦ç†
                st.session_state.recording_state["is_recording"] = True
                st.session_state.recorded_frames = []  # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                recording_status_placeholder.warning("éŒ²éŸ³ä¸­... è©±ã—çµ‚ã‚ã£ãŸã‚‰ã€ŒéŒ²éŸ³åœæ­¢ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ™ï¸")
                st.toast("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ", icon="ğŸ™ï¸")
                st.experimental_rerun()  # UIã‚’æ›´æ–°
            with col2:
                # éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ï¼ˆéŒ²éŸ³ä¸­ã®ã¿æœ‰åŠ¹ï¼‰
                stop_button = st.button(
                    "éŒ²éŸ³åœæ­¢", 
                    disabled=not st.session_state.recording_state["is_recording"],
                    key="stop_rec_button"
                )
                if stop_button:
                    # éŒ²éŸ³åœæ­¢å‡¦ç†
                    st.session_state.recording_state["is_recording"] = False
                    recording_status_placeholder.success("éŒ²éŸ³ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸã€‚", icon="âœ…")
                    st.toast("éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ", icon="âœ…")

                    # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ã®çµåˆã¨ä¿å­˜ï¼‰
                    if len(st.session_state.recorded_frames) > 0:
                        # ã“ã“ã§ process_recorded_audio() ã‚’å‘¼ã³å‡ºã™äºˆå®š
                        recording_status_placeholder.success("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ãŒã§ãã¾ã—ãŸ", icon="âœ…")
                    else:
                        recording_status_placeholder.error("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", icon="âŒ")
                    
                    st.experimental_rerun()  # UIã‚’æ›´æ–°

    else:
        # WebRTCæ¥ç¶šãŒç„¡åŠ¹ãªå ´åˆ
        status_placeholder.warning("ãƒã‚¤ã‚¯ãŒæ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ããƒã‚¤ã‚¯ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ¤")

def configure_webrtc():
    """WebRTCã®è¨­å®šã‚’è¡Œã†é–¢æ•°"""
    return webrtc_streamer(
        key="speech-recorder-config",
        mode=WebRtcMode.SENDONLY,
        audio_frame_callback=audio_frame_callback,
        rtc_configuration={
            "iceServers": [
                {"urls": ["stun:stun.l.google.com:19302"]},
                {"urls": ["stun:stun1.l.google.com:19302"]},
                {"urls": ["stun:stun2.l.google.com:19302"]},
                {"urls": ["stun:stun3.l.google.com:19302"]},
                {"urls": ["stun:stun4.l.google.com:19302"]},
            ],
            "iceTransportPolicy": "all",
            "iceCandidatePoolSize": 10,
            "bundlePolicy": "max-bundle",
            "rtcpMuxPolicy": "require"
        },
        media_stream_constraints={
            "video": False, 
            "audio": {
                "echoCancellation": True,
                "noiseSuppression": True,
                "autoGainControl": True,
            }
        },
        async_processing=True,
    )
def process_recorded_audio(analysis_placeholder):
    """éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦éŸ³å£°åˆ†æã‚’è¡Œã†é–¢æ•°"""
    if len(st.session_state.recorded_frames) == 0:
        st.warning("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å†åº¦éŒ²éŸ³ã—ã¦ãã ã•ã„ã€‚")
        return
    
    try:
        # éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
        audio_data = np.concatenate(st.session_state.recorded_frames, axis=0)
        sample_rate = 48000  # WebRTCã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        
        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            scipy.io.wavfile.write(tmp_file.name, sample_rate, audio_data)
            st.session_state.recorded_audio_path = tmp_file.name
            
        # éŸ³å£°åˆ†æ
        y, sr = librosa.load(st.session_state.recorded_audio_path, sr=None)
        
        # ç‰¹å¾´é‡æŠ½å‡ºï¼ˆæ—¢å­˜ã®é–¢æ•°ã‚’åˆ©ç”¨ï¼‰
        features = feature_extractor.extract_features(y, sr)
        
        # åˆ†æçµæœè¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆ
        with analysis_placeholder.container():
            st.subheader("éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°")
            st.audio(st.session_state.recorded_audio_path, format="audio/wav")
            
            # éŸ³å£°æ³¢å½¢ã¨éŸ³é‡å¤‰åŒ–ã®ã‚°ãƒ©ãƒ•è¡¨ç¤º
            st.subheader("éŸ³å£°åˆ†æ")
            fig = plot_audio_analysis(features, y, sr)
            st.pyplot(fig)
            
            # éŸ³é‡åˆ†æçµæœã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
            st.markdown('<h2 class="sub-header">éŸ³é‡åˆ†æçµæœ</h2>', unsafe_allow_html=True)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("å¹³å‡éŸ³é‡", f"{features['mean_volume']:.4f}")
                st.metric("æ–‡é ­éŸ³é‡", f"{features['start_volume']:.4f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("æ–‡ä¸­éŸ³é‡", f"{features['middle_volume']:.4f}")
                st.metric("æ–‡æœ«éŸ³é‡", f"{features['end_volume']:.4f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col3:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡", f"{features['end_drop_rate']:.2f}")
                if 'last_20_percent_drop_rate' in features:
                    st.metric("æœ€å¾Œã®20%éŸ³é‡ä½ä¸‹ç‡", f"{features['last_20_percent_drop_rate']:.2f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            # æ˜ç­åº¦è©•ä¾¡
            evaluation = evaluate_clarity(features)
            
            st.markdown('<h2 class="sub-header">æ˜ç­åº¦è©•ä¾¡</h2>', unsafe_allow_html=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("æ˜ç­åº¦ã‚¹ã‚³ã‚¢", f"{evaluation['score']}/100")
                st.metric("è©•ä¾¡", evaluation["clarity_level"])
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.subheader("ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                st.write(evaluation["advice"])
                st.markdown('</div>', unsafe_allow_html=True)
            
            # è¿½åŠ : è©³ç´°ãªç‰¹å¾´é‡è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if st.checkbox("è©³ç´°ãªç‰¹å¾´é‡ã‚’è¡¨ç¤º", key="show_detailed_features"):
                st.subheader("æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡")
                
                # ç‰¹å¾´é‡ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†ã—ã¦è¡¨ç¤º
                volume_features = {k: v for k, v in features.items() if 'volume' in k or 'rms' in k or 'drop' in k}
                spectral_features = {k: v for k, v in features.items() if 'spectral' in k or 'mfcc' in k}
                rhythm_features = {k: v for k, v in features.items() if 'onset' in k or 'speech' in k}
                
                st.write("### éŸ³é‡é–¢é€£ç‰¹å¾´é‡")
                st.write(pd.DataFrame({
                    'ç‰¹å¾´é‡': list(volume_features.keys()),
                    'å€¤': list(volume_features.values())
                }))
                
                if spectral_features:
                    st.write("### ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡")
                    st.write(pd.DataFrame({
                        'ç‰¹å¾´é‡': list(spectral_features.keys()),
                        'å€¤': list(spectral_features.values())
                    }))
                
                if rhythm_features:
                    st.write("### ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡")
                    st.write(pd.DataFrame({
                        'ç‰¹å¾´é‡': list(rhythm_features.keys()),
                        'å€¤': list(rhythm_features.values())
                    }))
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¯å¿…è¦ã«å¿œã˜ã¦å®Ÿè£…
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        st.error(f"éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        import traceback
        st.code(traceback.format_exc())
                         

# ä¼šè©±ã‚µãƒ³ãƒ—ãƒ«
CONVERSATION_SAMPLES = {
    "å®¶æ—ã¨ã®ä¼šè©±": [
        "ä»Šæ—¥ã®å¤•é£Ÿã€ä½•ã«ã™ã‚‹ï¼Ÿãƒ‘ã‚¹ã‚¿ã§ã„ã„ï¼Ÿ",
        "ã•ã£ãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹ãŸï¼Ÿãªã‚“ã‹é¢ç™½ã‹ã£ãŸã­",
        "åœŸæ›œæ—¥ã¯ä½•ã‹äºˆå®šã‚ã‚‹ï¼Ÿè²·ã„ç‰©ã«è¡Œã“ã†ã‹ãªã¨æ€ã£ã¦ã‚‹ã‚“ã ã‘ã©"
    ],
    "å‹äººã¨ã®ä¼šè©±": [
        "ã“ã®é–“ã®è©±ã®ç¶šããªã‚“ã ã‘ã©ã€çµå±€ã©ã†ãªã£ãŸã®ï¼Ÿ",
        "æ–°ã—ã„ã‚«ãƒ•ã‚§è¦‹ã¤ã‘ãŸã‚“ã ã€‚ä»Šåº¦ä¸€ç·’ã«è¡Œã‹ãªã„ï¼Ÿ",
        "æœ€è¿‘ã©ã†ï¼Ÿä½•ã‹å¤‰ã‚ã£ãŸã“ã¨ã‚ã£ãŸï¼Ÿ"
    ],
    "æ‹äººã¨ã®ä¼šè©±": [
        "ã¡ã‚‡ã£ã¨ã“ã‚Œæ‰‹ä¼ã£ã¦ã‚‚ã‚‰ãˆã‚‹ï¼Ÿã™ãçµ‚ã‚ã‚‹ã‹ã‚‰",
        "çª“é–‹ã‘ã¦ã‚‚ã‚‰ã£ã¦ã‚‚ã„ã„ï¼Ÿã¡ã‚‡ã£ã¨æš‘ã„ã¨æ€ã£ã¦",
        "ã‚ã®ã­ã€æ˜¨æ—¥è¦‹ãŸæ˜ ç”»ãŒã™ã”ãè‰¯ã‹ã£ãŸã‚“ã "
    ]
}
# éŸ³å£°åˆ†æã®ãŸã‚ã®ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã®å®šç¾©
class VoiceFeatureExtractor:
    """éŸ³å£°ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def extract_features(self, audio_data, sr):
        """éŸ³å£°ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°"""
        features = {}
        
        # åŸºæœ¬çš„ãªéŸ³é‡ç‰¹å¾´é‡ï¼ˆRMSï¼‰
        rms = librosa.feature.rms(y=audio_data)[0]
        times = librosa.times_like(rms, sr=sr)
        features['rms'] = rms
        features['times'] = times
        features['mean_volume'] = np.mean(rms)
        features['std_volume'] = np.std(rms)
        features['max_volume'] = np.max(rms)
        features['min_volume'] = np.min(rms)
        
        # ä¼šè©±éŸ³å£°ã‚’ä¸‰åˆ†å‰²ã—ãŸåˆ†æ
        third = len(rms) // 3
        features['start_volume'] = np.mean(rms[:third])  # æœ€åˆã®1/3
        features['middle_volume'] = np.mean(rms[third:2*third])  # ä¸­é–“ã®1/3
        features['end_volume'] = np.mean(rms[2*third:])  # æœ€å¾Œã®1/3
        
        # æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡ã®è¨ˆç®—
        features['end_drop_rate'] = (features['middle_volume'] - features['end_volume']) / features['middle_volume'] if features['middle_volume'] > 0 else 0
        
        # è¿½åŠ : ã‚ˆã‚Šè©³ç´°ãªæ–‡æœ«åˆ†æï¼ˆæœ€å¾Œã®20%éƒ¨åˆ†ï¼‰
        end_portion = max(1, int(len(rms) * 0.2))  # æœ€å¾Œã®20%
        features['last_20_percent_volume'] = np.mean(rms[-end_portion:])
        features['last_20_percent_drop_rate'] = (features['mean_volume'] - features['last_20_percent_volume']) / features['mean_volume'] if features['mean_volume'] > 0 else 0
        
        # è¿½åŠ : MFCCç‰¹å¾´é‡ï¼ˆéŸ³å£°ã®éŸ³è‰²ç‰¹æ€§ï¼‰
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
        for i in range(len(mfccs)):
            features[f'mfcc_{i+1}_mean'] = np.mean(mfccs[i])
            features[f'mfcc_{i+1}_std'] = np.std(mfccs[i])
        
        # è¿½åŠ : ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹æ€§
        spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sr)[0]
        features['spectral_centroid_mean'] = np.mean(spectral_centroid)
        
        # è¿½åŠ : éŸ³å£°ã®ãƒšãƒ¼ã‚¹ï¼ˆã‚ªãƒ³ã‚»ãƒƒãƒˆæ¤œå‡ºã§éŸ³ç¯€ã‚’è¿‘ä¼¼ï¼‰
        onset_env = librosa.onset.onset_strength(y=audio_data, sr=sr)
        onsets = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)
        features['onset_count'] = len(onsets)
        features['speech_rate'] = len(onsets) / (len(audio_data) / sr) if len(audio_data) > 0 else 0
        
        return features

def analyze_volume(y, sr):
    """åŸºæœ¬çš„ãªéŸ³é‡åˆ†æã‚’è¡Œã†é–¢æ•°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰"""
    extractor = VoiceFeatureExtractor()
    features = extractor.extract_features(y, sr)
    
    # å…ƒã®é–¢æ•°ã¨åŒã˜ã‚­ãƒ¼ã¨å€¤ã‚’è¿”ã™
    return {
        "rms": features["rms"],
        "times": features["times"],
        "mean_volume": features["mean_volume"],
        "std_volume": features["std_volume"],
        "max_volume": features["max_volume"],
        "min_volume": features["min_volume"],
        "start_volume": features["start_volume"],
        "middle_volume": features["middle_volume"],
        "end_volume": features["end_volume"],
        "end_drop_rate": features["end_drop_rate"]
    }

def plot_audio_analysis(features, audio_data, sr):
    """éŸ³å£°åˆ†æã®è¦–è¦šåŒ–ã‚’è¡Œã†é–¢æ•°"""
    # 2ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
    
    # 1ã¤ç›®ã®ãƒ—ãƒ­ãƒƒãƒˆ: æ³¢å½¢è¡¨ç¤º
    librosa.display.waveshow(audio_data, sr=sr, ax=ax1)
    ax1.set_title('éŸ³å£°æ³¢å½¢')
    ax1.set_xlabel('æ™‚é–“ (ç§’)')
    ax1.set_ylabel('æŒ¯å¹…')
    
    # 2ã¤ç›®ã®ãƒ—ãƒ­ãƒƒãƒˆ: éŸ³é‡å¤‰åŒ–
    rms = features['rms']
    times = features['times']
    ax2.plot(times, rms, color='blue', label='éŸ³é‡ (RMS)')
    ax2.set_title('éŸ³é‡å¤‰åŒ–')
    ax2.set_xlabel('æ™‚é–“ (ç§’)')
    ax2.set_ylabel('éŸ³é‡ (RMS)')
    
    # æ–‡æœ«éƒ¨åˆ†ï¼ˆæœ€å¾Œã®20%ï¼‰ã‚’å¼·èª¿è¡¨ç¤º
    if len(times) > 0:
        end_portion = max(1, int(len(times) * 0.2))  # æœ€å¾Œã®20%
        start_highlight = times[-end_portion]
        end_time = times[-1]
        ax2.axvspan(start_highlight, end_time, color='red', alpha=0.2)
        ax2.text(start_highlight + (end_time - start_highlight)/10, 
               max(rms) * 0.8, 'æ–‡æœ«éƒ¨åˆ† (æœ€å¾Œã®20%)', color='red')
    
    # æ–‡é ­ãƒ»æ–‡ä¸­ãƒ»æ–‡æœ«ã®å¹³å‡éŸ³é‡ã‚’æ°´å¹³ç·šã§è¡¨ç¤º
    ax2.axhline(y=features['start_volume'], color='green', linestyle='--', label='æ–‡é ­å¹³å‡')
    ax2.axhline(y=features['middle_volume'], color='orange', linestyle='--', label='æ–‡ä¸­å¹³å‡')
    ax2.axhline(y=features['end_volume'], color='red', linestyle='--', label='æ–‡æœ«å¹³å‡')
    ax2.legend()
    
    plt.tight_layout()
    return fig

def evaluate_clarity(features):
    """éŸ³é‡ç‰¹å¾´ã‹ã‚‰ã‚¯ãƒªã‚¢ãªç™ºè©±ã‹ã©ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹é–¢æ•°"""
    drop_rate = features["end_drop_rate"]
    last_20_drop_rate = features.get("last_20_percent_drop_rate", 0)  # ã‚­ãƒ¼ãŒãªã„å ´åˆã¯0
    
    # ä¸¡æ–¹ã®ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã‚’è€ƒæ…®ã—ãŸè©•ä¾¡
    avg_drop_rate = (drop_rate + last_20_drop_rate) / 2
    
    if avg_drop_rate < 0.1:
        clarity_level = "è‰¯å¥½"
        advice = "èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºè©±ã§ãã¦ã„ã¾ã™ï¼ç´ æ™´ã‚‰ã—ã„ãƒãƒ©ãƒ³ã‚¹ã§ã™ã€‚"
        score = min(100, int((1 - avg_drop_rate) * 100))
    elif avg_drop_rate < 0.25:
        clarity_level = "æ™®é€š"
        advice = "èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ–‡æœ«ã‚’æ„è­˜ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚"
        score = int(75 - (avg_drop_rate - 0.1) * 100)
    elif avg_drop_rate < 0.4:
        clarity_level = "ã‚„ã‚„å¼±ã„"
        advice = "æ–‡æœ«ã®éŸ³é‡ãŒã‹ãªã‚Šä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’1éŸ³ä¸Šã’ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
        score = int(60 - (avg_drop_rate - 0.25) * 100)
    else:
        clarity_level = "æ”¹å–„å¿…è¦"
        advice = "èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ—¥æœ¬èªã¯æ–‡æœ«ã«é‡è¦ãªæƒ…å ±ã‚„çµè«–ãŒæ¥ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€æ–‡æœ«ã¾ã§æ„è­˜ã—ã¦ç›¸æ‰‹ã«ä¼ãˆã‚‹ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†ã€‚"
        score = max(20, int(40 - (avg_drop_rate - 0.4) * 50))
    
    return {
        "clarity_level": clarity_level,
        "advice": advice,
        "score": score,
        "avg_drop_rate": avg_drop_rate
    }

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
feature_extractor = VoiceFeatureExtractor()

# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.title('èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼')
st.write('èº«è¿‘ãªä¼šè©±ã‚’ã—ã£ã‹ã‚Šä¼ãˆã‚‹ã“ã¨ã§ã€å¤§åˆ‡ãªäººã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã‚ˆã†')

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸é¸æŠ", ["ãƒ›ãƒ¼ãƒ ", "ç·´ç¿’ã‚’å§‹ã‚ã‚‹", "æœ¬ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦"])

# ç‰¹å¾´æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
feature_extractor = VoiceFeatureExtractor()

# ãƒšãƒ¼ã‚¸ã”ã¨ã®è¡¨ç¤ºå†…å®¹
if page == "ãƒ›ãƒ¼ãƒ ":
    st.markdown('<h1 class="main-header">Welcomeï¼</h1>', unsafe_allow_html=True)
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.write("""
    ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®çŸ­ã„ä¼šè©±ã‚’åˆ†æã—ã€æ–‡æœ«ã®æ˜ç­ã•ã‚’é«˜ã‚ã‚‹ã“ã¨ã«æ³¨åŠ›ã—ã¦ã„ã¾ã™ã€‚
    æ—¥æœ¬èªã¯è¨€èªã®ç‰¹å¾´ä¸Šã€è‡ªç„¶ã¨èªå°¾ã®éŸ³å£°é‡ãŒä½ä¸‹ã—ãŒã¡ã§ã™ã€‚
    å®¶æ—ã‚„è¿‘ã—ã„äººã¨ã®ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªä¼šè©±ã‚„ã€å°å£°ã®ä¼šè©±ã§ç‰¹ã«ã“ã®å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚
    ä¸€æ–¹ã§æ„è­˜ã—ã™ãã¦å¤§ãã™ããŸã‚Šã€åŠ›ã‚’å…¥ã‚Œã™ãã‚‹ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãƒã‚¤ãƒŠã‚¹ã§ã™ã€‚
    ã‚ãªãŸã®ç™ºè©±ã‚’åˆ†æã—ã¦ã€è©±ã—æ–¹ã‚’é«˜ã‚ã‚‹ãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
    ãœã²ã€ã‚ãªãŸã®å£°ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚            
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('<h2 class="sub-header">ä½¿ã„æ–¹</h2>', unsafe_allow_html=True)
    st.write("1. ä¸‹ã®ãƒœã‚¿ãƒ³ã€ã¾ãŸã¯å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œç·´ç¿’ã‚’å§‹ã‚ã‚‹ã€ã‚’é¸æŠ")
    st.write("2. ç·´ç¿’ã—ãŸã„ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’é¸ã‚“ã§èª­ã¿ä¸Šã’ã‚‹")
    st.write("3. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.write("4. åˆ†æçµæœã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç¢ºèª")
    
    if st.button("ç·´ç¿’ã‚’å§‹ã‚ã‚‹"):
        st.session_state.page = "ç·´ç¿’ã‚’å§‹ã‚ã‚‹"
        st.experimental_rerun() 


elif page == "ç·´ç¿’ã‚’å§‹ã‚ã‚‹":
    st.markdown('<h1 class="sub-header">éŸ³å£°ç·´ç¿’</h1>', unsafe_allow_html=True)
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ã‚µãƒ³ãƒ—ãƒ«æ–‡ã®é¸æŠ
    category = st.selectbox("ä¼šè©±ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ", list(CONVERSATION_SAMPLES.keys()))
    sample_index = st.selectbox(
        "ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’é¸æŠ", 
        range(len(CONVERSATION_SAMPLES[category])),
        format_func=lambda i: CONVERSATION_SAMPLES[category][i]
    )
    
    selected_sample = CONVERSATION_SAMPLES[category][sample_index]
    
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.write("### èª­ã¿ä¸Šã’ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ–‡")
    st.write(selected_sample)
    st.write("ã“ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’ã€æ™®æ®µã®ã‚ˆã†ã«è‡ªç„¶ã«èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚")
    st.markdown('</div>', unsafe_allow_html=True)

    # éŸ³å£°å…¥åŠ›æ–¹æ³•ã®é¸æŠ
    st.session_state.input_method = st.radio("éŸ³å£°å…¥åŠ›æ–¹æ³•", ["éŒ²éŸ³ã™ã‚‹", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"],key="unique_key_1") 

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®æº–å‚™ï¼ˆå‹•çš„æ›´æ–°ç”¨ï¼‰
    status_placeholder = st.empty()
    volume_placeholder = st.empty()
    recording_status_placeholder = st.empty()
    analysis_placeholder = st.empty()
    

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
    if "input_method" not in st.session_state:
        st.session_state.input_method = "éŒ²éŸ³ã™ã‚‹"
  
    #å…¥åŠ›æ–¹æ³•ã«å¿œã˜ãŸå‡¦ç†
    if st.session_state.input_method == "éŒ²éŸ³ã™ã‚‹":
        st.write("éŒ²éŸ³æ©Ÿèƒ½ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
        st.info("ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ãƒã‚¤ã‚¯ä½¿ç”¨è¨±å¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ‰¿èªã—ã¦ãã ã•ã„ã€‚")
    
    elif st.session_state.input_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_file = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", 
            type=["wav", "mp3"],
            key="simple_uploader"
            )
        if uploaded_file is not None:
            st.write(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}")
    
    # éŸ³å£°å…¥åŠ›æ–¹æ³•ã®é¸æŠï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼‰ 
    st.session_state.input_method = st.radio("éŸ³å£°å…¥åŠ›æ–¹æ³•", ["éŒ²éŸ³ã™ã‚‹", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"], key="input_method_radio_unique")
          
    # éŒ²éŸ³ã™ã‚‹å ´åˆã®å‡¦ç†
    if st.session_state.input_method == "éŒ²éŸ³ã™ã‚‹":
        st.write("### ãƒã‚¤ã‚¯ã§éŒ²éŸ³")
        st.info("ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ãƒã‚¤ã‚¯ä½¿ç”¨è¨±å¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ‰¿èªã—ã¦ãã ã•ã„ã€‚")  

    # éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«è¡¨ç¤º
    st.session_state.input_method = st.radio("éŸ³å£°å…¥åŠ›æ–¹æ³•", ["éŒ²éŸ³ã™ã‚‹", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"], key="input_method_radio_2")
    
    webrtc_ctx = configure_webrtc() 

    # WebRTCæ¥ç¶šãŒæœ‰åŠ¹ãªå ´åˆã®å‡¦ç†
    if webrtc_ctx.state.playing:
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼è¡¨ç¤º
        display_volume_meter(volume_placeholder)

    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
        show_debug_info(webrtc_ctx)
  
    # WebRTCéŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°    

    webrtc_ctx = webrtc_streamer(
        key="speech-recorder-main",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=256,  
        rtc_configuration={
            "iceServers": [
                {"urls": ["stun:stun.l.google.com:19302"]},
                {"urls": ["stun:stun1.l.google.com:19302"]},
                {"urls": ["stun:stun2.l.google.com:19302"]},
                {"urls": ["stun:stun3.l.google.com:19302"]},
                {"urls": ["stun:stun4.l.google.com:19302"]},
                ],
            "iceTransportPolicy": "all",
            "iceCandidatePoolSize": 10,
            "bundlePolicy": "max-bundle",
            "rtcpMuxPolicy": "require"
        },
        media_stream_constraints={
            "video": False, 
            "audio": {
                "echoCancellation": True,
                "noiseSuppression": True,
                "autoGainControl": True,
            }
        },
        async_processing=False, # éåŒæœŸå‡¦ç†ã‚’ç„¡åŠ¹ã«ã™ã‚‹
    )

    # WebRTCæ¥ç¶šãŒæœ‰åŠ¹ãªå ´åˆ
    if webrtc_ctx.state.playing:
        st.success("WebRTCæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¾ã—ãŸã€‚éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        
        # éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
        col1, col2 = st.columns(2)

        with col1:
            if st.button("éŒ²éŸ³é–‹å§‹", key="start_recording"):

                st.session_state.recording_state["is_recording"] = True
                st.session_state.recorded_frames = []      
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’æ›´æ–°
                global_recording_state["is_recording"] = True
                global_recorded_frames.clear()  # éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¯ãƒªã‚¢
                st.success("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚")
                st.write(f"éŒ²éŸ³ä¸­ãƒ•ãƒ©ã‚°ï¼ˆsessionï¼‰: {st.session_state.recording_state['is_recording']}")
                st.write(f"éŒ²éŸ³ä¸­ãƒ•ãƒ©ã‚°ï¼ˆglobalï¼‰: {global_recording_state['is_recording']}")
        
        with col2:
            if st.button("éŒ²éŸ³åœæ­¢", key="stop_rec1"):
                st.write("éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸ")
                st.write(f"éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆglobalï¼‰: {len(global_recorded_frames)}")

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                st.session_state.recording_state["is_recording"] = False

                # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’æ›´æ–°
                global_recording_state["is_recording"] = False
                
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã™ã‚‹
                if len(global_recorded_frames) > 0:
                    try:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
                        audio_data = np.concatenate(global_recorded_frames, axis=0)
                        sample_rate = 48000  # WebRTCã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ               
                
                        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                            scipy.io.wavfile.write(tmp_file.name, sample_rate, audio_data)
                            st.session_state.recorded_audio = tmp_file.name
                            #session_stateã«éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ä¿å­˜(UIã®æ›´æ–°ç”¨)
                            st.session_state.recorded_frames = global_recorded_frames.copy()  # â† ã“ã“è¿½åŠ ï¼
                            st.success(f"éŒ²éŸ³å®Œäº†ï¼ãƒ•ã‚¡ã‚¤ãƒ«ï¼š{tmp_file.name}")
                           
                    except Exception as e:
                        st.error(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:
                st.warning("WebRTCæ¥ç¶š: ç„¡åŠ¹ã€‚ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã‹ã‚‰éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„ã€‚")
        

    #éŒ²éŸ³çŠ¶æ…‹ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
    st.write("## ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
    st.write(f"WebRTCã®çŠ¶æ…‹: {webrtc_ctx.state}")
    st.write(f"éŒ²éŸ³çŠ¶æ…‹: {global_recording_state}")
    st.write(f"éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(global_recorded_frames)}")
    st.write(f"audio_queueã®å‹: {type(audio_queue)}")

    if 'recorded_audio' in st.session_state:
        st.write(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹: {st.session_state.recorded_audio}")
    else:
        st.write("éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“")
    
    # WebRTCã®è©³ç´°ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
    if st.checkbox("è©³ç´°ãªWebRTCãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º"):
        st.write("### è©³ç´°WebRTCãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        st.write(f"WebRTCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å±æ€§: {dir(webrtc_ctx)}")
    
    if webrtc_ctx.state.playing:
        st.write("WebRTCæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¾ã—ãŸ: æœ‰åŠ¹")
        
        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒƒã‚¯æƒ…å ±ã®å–å¾—ã‚’è©¦ã¿ã‚‹
        try:
            st.write("æ¥ç¶šçŠ¶æ…‹ã®è©³ç´°ç¢ºèªä¸­...")
            # é€²è¡ŒçŠ¶æ³ãƒãƒ¼ã‚’è¡¨ç¤º
            progress_bar = st.progress(0)
            for i in range(1, 4):
                time.sleep(0.5)  # å°‘ã—å¾…æ©Ÿ
                progress_bar.progress(i/3)
                st.write(f"çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ {i}: {webrtc_ctx.state}")
            
            st.success("WebRTCæ¥ç¶šã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        except Exception as e:
            st.error(f"WebRTCè©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚‹ã‹ç¢ºèª
        if len(st.session_state.recorded_frames) > 0:
                    try:
                        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ã®çµåˆã¨ä¿å­˜ï¼‰
                        audio_data = np.concatenate(st.session_state.recorded_frames, axis=0)               
                
                        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                            sample_rate = 48000  # WebRTCã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
                            scipy.io.wavfile.write(tmp_file.name, sample_rate, audio_data)
                            st.session_state.recorded_audio = tmp_file.name
                            st.success(f"éŒ²éŸ³å®Œäº†ï¼ãƒ•ã‚¡ã‚¤ãƒ«ï¼š{tmp_file.name}")
                    except Exception as e:
                        st.error(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        else:
                #æ¥ç¶šãŒç„¡åŠ¹ãªå ´åˆ
                st.warning("éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€ŒéŒ²éŸ³é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã‹ã‚‰éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„ã€‚")    
               
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        st.write("åœæ­¢ãƒœã‚¿ãƒ³æŠ¼ä¸‹å¾Œ:")
        st.write(f"éŒ²éŸ³çŠ¶æ…‹: {st.session_state.recording_state}")
        st.write(f"éŒ²éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(st.session_state.recorded_frames)}")
                
        if len(st.session_state.recorded_frames) > 0:
                    # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    audio_data = np.concatenate(st.session_state.recorded_frames, axis=0) 
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                        # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆä»®å®šï¼ˆå®Ÿéš›ã¯webrtc_ctxã‹ã‚‰å–å¾—ã™ã‚‹ã¹ãï¼‰
                        sample_rate = 48000
                        import scipy.io.wavfile as wavfile
                        wavfile.write(tmp_file.name, sample_rate, audio_data)
                        st.session_state.recorded_audio = tmp_file.name
                        st.success("éŒ²éŸ³å®Œäº†ï¼ä»¥ä¸‹ã§å†ç”Ÿã¨åˆ†æãŒã§ãã¾ã™")

        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤ºã¨åˆ†æ
        if 'recorded_audio' in st.session_state and st.session_state.recorded_audio:
            if os.path.exists(st.session_state.recorded_audio): # éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
               st.audio(st.session_state.recorded_audio, format='audio/wav')
               
               if st.button("éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’åˆ†æ"):
                try:
                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
                    st.write("åˆ†æãƒœã‚¿ãƒ³æŠ¼ä¸‹:")
                    st.write(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {st.session_state.recorded_audio}")
                    st.write(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª: {os.path.exists(st.session_state.recorded_audio)}")

                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                    y, sr = librosa.load(st.session_state.recorded_audio, sr=None)  
                    
                    # èª­ã¿è¾¼ã¿å¾Œã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                    st.write(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®é•·ã•: {len(y)}")
                    st.write(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sr}")
                    
                    # ç‰¹å¾´é‡æŠ½å‡º
                    features = analyze_volume(y, sr)
                    
                    # ä»¥ä¸‹ã€åˆ†æè¡¨ç¤ºã®ã‚³ãƒ¼ãƒ‰
                    # æ³¢å½¢ã®è¡¨ç¤º
                    st.subheader("éŸ³å£°æ³¢å½¢")
                    fig, ax = plt.subplots(figsize=(10, 4))
                    librosa.display.waveshow(y, sr=sr, ax=ax)
                    ax.set_xlabel('æ™‚é–“ (ç§’)')
                    ax.set_ylabel('æŒ¯å¹…')
                    st.pyplot(fig)
                    
                    # éŸ³é‡å¤‰åŒ–ã®ã‚°ãƒ©ãƒ•è¡¨ç¤º
                    st.subheader("éŸ³é‡åˆ†æ")
                    fig, ax = plt.subplots(figsize=(10, 4))
                    ax.plot(features["times"], features["rms"], color='blue')
                    ax.set_xlabel('æ™‚é–“ (ç§’)')
                    ax.set_ylabel('éŸ³é‡ (RMS)')
                    
                    # æ–‡æœ«éƒ¨åˆ†ï¼ˆæœ€å¾Œã®1/3ï¼‰ã‚’å¼·èª¿è¡¨ç¤º
                    if len(features["times"]) > 0:
                        third = len(features["times"]) // 3
                        start_highlight = features["times"][2*third]
                        end_time = features["times"][-1]
                        ax.axvspan(start_highlight, end_time, color='red', alpha=0.2)
                        ax.text(start_highlight + (end_time - start_highlight)/10, 
                               max(features["rms"]) * 0.8, 'æ–‡æœ«éƒ¨åˆ†', color='red')
                    st.pyplot(fig)
                    
                    # éŸ³é‡åˆ†æçµæœã®è¡¨ç¤ºï¼ˆç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜ï¼‰
                    st.subheader("éŸ³é‡åˆ†æçµæœ")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("å¹³å‡éŸ³é‡", f"{features['mean_volume']:.4f}")
                        st.metric("æ–‡é ­éŸ³é‡", f"{features['start_volume']:.4f}")
                    
                    with col2:
                        st.metric("æœ€å¤§éŸ³é‡", f"{features['max_volume']:.4f}")
                        st.metric("æ–‡ä¸­éŸ³é‡", f"{features['middle_volume']:.4f}")
                    
                    with col3:
                        st.metric("æœ€å°éŸ³é‡", f"{features['min_volume']:.4f}")
                        st.metric("æ–‡æœ«éŸ³é‡", f"{features['end_volume']:.4f}")
                    
                    # æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡ã¨ç°¡å˜ãªè©•ä¾¡
                    st.subheader("æ–‡æœ«éŸ³é‡åˆ†æ")
                    
                    drop_rate = features["end_drop_rate"]
                    st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡", f"{drop_rate:.2f}")
                    
                    if drop_rate < 0.1:
                        st.success("èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºéŸ³ã§ãã¦ã„ã¾ã™ï¼")
                    elif drop_rate < 0.3:
                        st.info("èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ„è­˜ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                    else:
                        st.warning("èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã¾ã§æ„è­˜ã—ã¦ç™ºéŸ³ã™ã‚‹ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†ã€‚")
                
                except Exception as e:
                    st.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å‡¦ç†
import os

# æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã®ãƒã‚§ãƒƒã‚¯ã‚’å¼·åŒ–
def is_valid_audio_file(file):
    if file is None:
        return False
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã¦æ‹¡å¼µå­ã‚’ãƒã‚§ãƒƒã‚¯
    filename = file.name.lower()
    return filename.endswith(".wav") or filename.endswith(".mp3")

if st.session_state.input_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", 
        type=["wav", "mp3"],
        key="uploader123"
        )
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæœ‰åŠ¹ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    if uploaded_file is not None:
        file_name =uploaded_file.name
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
      
    #ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    if uploaded_file is not None:
        st.write("### ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        st.write(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«å: {uploaded_file.name}")
        st.write(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—: {uploaded_file.type}")
        st.write(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {uploaded_file.size} ãƒã‚¤ãƒˆ")

        #ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’å–å¾—
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        st.write(f"æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­: {file_ext}")
        st.write(f'è¨±å¯ã•ã‚Œã¦ã„ã‚‹æ‹¡å¼µå­:[".wav",".mp3"]')
        st.write(f'æ‹¡å¼µå­ã¯è¨±å¯ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ã¾ã™: {file_ext in [".wav", ".mp3"]}')

   
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿå¯èƒ½ã«è¡¨ç¤º
        audio_format = "audio/wav" if file_ext == ".wav" else "audio/mp3"
        st.audio(tmp_file_path, format=audio_format)
                
        try:
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            y, sr = librosa.load(tmp_file_path, sr=None)
            
            # ç‰¹å¾´é‡æŠ½å‡º
            features = feature_extractor.extract_features(y, sr)
            
            # éŸ³å£°åˆ†æã®ã‚°ãƒ©ãƒ•è¡¨ç¤º
            st.subheader("éŸ³å£°åˆ†æ")
            fig = plot_audio_analysis(features, y, sr)
            st.pyplot(fig)
            
            # éŸ³é‡åˆ†æçµæœã‚’è¡¨ç¤º
            st.markdown('<h2 class="sub-header">éŸ³é‡åˆ†æçµæœ</h2>', unsafe_allow_html=True)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("å¹³å‡éŸ³é‡", f"{features['mean_volume']:.4f}")
                st.metric("æ–‡é ­éŸ³é‡", f"{features['start_volume']:.4f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("æ–‡ä¸­éŸ³é‡", f"{features['middle_volume']:.4f}")
                st.metric("æ–‡æœ«éŸ³é‡", f"{features['end_volume']:.4f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col3:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡", f"{features['end_drop_rate']:.2f}")
                st.metric("æœ€å¾Œã®20%éŸ³é‡ä½ä¸‹ç‡", f"{features['last_20_percent_drop_rate']:.2f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            # æ˜ç­åº¦è©•ä¾¡
            evaluation = evaluate_clarity(features)
            
            st.markdown('<h2 class="sub-header">æ˜ç­åº¦è©•ä¾¡</h2>', unsafe_allow_html=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.metric("æ˜ç­åº¦ã‚¹ã‚³ã‚¢", f"{evaluation['score']}/100")
                st.metric("è©•ä¾¡", evaluation["clarity_level"])
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                st.subheader("ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                st.write(evaluation["advice"])
                st.markdown('</div>', unsafe_allow_html=True)
            
            # è¿½åŠ : è©³ç´°ãªç‰¹å¾´é‡è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if st.checkbox("è©³ç´°ãªç‰¹å¾´é‡ã‚’è¡¨ç¤º"):
                st.subheader("æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡")
                
                # ç‰¹å¾´é‡ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†ã—ã¦è¡¨ç¤º
                volume_features = {k: v for k, v in features.items() if 'volume' in k or 'rms' in k or 'drop' in k}
                spectral_features = {k: v for k, v in features.items() if 'spectral' in k or 'mfcc' in k}
                rhythm_features = {k: v for k, v in features.items() if 'onset' in k or 'speech' in k}
                
                st.write("### éŸ³é‡é–¢é€£ç‰¹å¾´é‡")
                st.write(pd.DataFrame({
                    'ç‰¹å¾´é‡': list(volume_features.keys()),
                    'å€¤': list(volume_features.values())
                }))
                
                st.write("### ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡")
                st.write(pd.DataFrame({
                    'ç‰¹å¾´é‡': list(spectral_features.keys()),
                    'å€¤': list(spectral_features.values())
                }))
                
                st.write("### ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡")
                st.write(pd.DataFrame({
                    'ç‰¹å¾´é‡': list(rhythm_features.keys()),
                    'å€¤': list(rhythm_features.values())
                }))
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(tmp_file_path)
            
        except Exception as e:
            st.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            try:
                os.unlink(tmp_file_path)
            except:
                pass

elif page == "ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦":
    st.header("ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦")
    st.write("""
    ## èªå°¾ãƒã‚¹ã‚¿ãƒ¼
    
    ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸéŸ³å£°åˆ†æã‚¢ãƒ—ãƒªã§ã™ã€‚
    ç‰¹ã«æ—¥æœ¬èªã®æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ã®å‚¾å‘ã‚’æ¤œå‡ºã—ã€ã‚ˆã‚Šæ˜ç¢ºãªç™ºè©±ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
    
    ### é–‹ç™ºç›®çš„
    - æ—¥æœ¬èªã®èªå°¾ã‚’ã¯ã£ãã‚Šä¼ãˆã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
    - ç‰¹ã«è¦ªå¯†ãª1å¯¾1ã§ã®ä¼šè©±ã«ãŠã‘ã‚‹æ˜ç­ã•ã®å‘ä¸Šã‚’ç›®æŒ‡ã—ã¾ã™
    - æ©Ÿæ¢°å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸéŸ³å£°åˆ†æã‚’å®Ÿç¾ã—ã¾ã™
    - æœ¬ã‚¢ãƒ—ãƒªã¯ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ç‰¹ã«æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨ã§ã€ç™ºè©±ã®æ˜ç­ã•ã‚’è©•ä¾¡ã—ã¾ã™
    
    ### ç•™æ„äº‹é …
    - æœ¬ã‚¢ãƒ—ãƒªã¯ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ãŸã‚ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é…æ…®ã—ã¦ãã ã•ã„
    - éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ã«ä¿å­˜ã•ã‚Œã€åˆ†æå¾Œã«å‰Šé™¤ã•ã‚Œã¾ã™
    - æœ¬ã‚¢ãƒ—ãƒªã¯ã€ä¸€èˆ¬çš„ãªéŸ³å£°åˆ†æã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€ç‰¹å®šã®å€‹äººã‚„çŠ¶æ³ã«å¯¾ã™ã‚‹è©•ä¾¡ã‚’è¡Œã†ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“
    - æœ¬ã‚¢ãƒ—ãƒªã¯ã€å°‚é–€çš„ãªéŸ³å£°åˆ†æãƒ„ãƒ¼ãƒ«ã§ã¯ãªãã€ã‚ãã¾ã§å‚è€ƒã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„
             
    
    ### ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½
    - éŸ³å£°æ³¢å½¢ã®è¡¨ç¤ºã¨åˆ†æ
    - æ–‡æœ«éŸ³é‡ä½ä¸‹ã®æ¤œå‡º
    - é©åˆ‡ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®æä¾›
    """)

# ã‚¢ãƒ—ãƒªã®èµ·å‹•å­—ã®ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
if __name__ == "__main__":
    print("ã‚¢ãƒ—ãƒªãŒèµ·å‹•ã•ã‚Œã¾ã—ãŸ")

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆã‚¢ãƒ—ãƒªã®è¦‹æ „ãˆã‚’ã‚ˆã‚Šã‚ˆã„ã‚‚ã®ã«ã™ã‚‹ãŸã‚ï¼‰
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 5px;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #F5F5F5;
        padding: 1rem;
        border-radius: 5px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)
