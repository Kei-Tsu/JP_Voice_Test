import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import librosa
import librosa.display
import tempfile
import os # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¿…è¦
import queue
import altair as alt # ã‚°ãƒ©ãƒ•æç”»ç”¨ 
import time
import asyncio
import logging
from pydub import AudioSegment

#æ©Ÿæ¢°å­¦ç¿’é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ml_model import VoiceQualityModel, generate_training_data

# éŸ³å£°åˆ†æé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from voice_analysis import VoiceFeatureExtractor, plot_audio_analysis, evaluate_clarity, get_feedback

# WebRTCé–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ:FFmpegè­¦å‘Šã®ç„¡è¦–è¨­å®šã‚’è¿½åŠ 
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning, message="Couldn't find ffmpeg or avconv")

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

# WebRTCé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
    WEBRTC_AVAILABLE = True# ãƒ–ãƒ©ã‚¦ã‚¶ã§éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
except ImportError:
    WEBRTC_AVAILABLE = False
    st.sidebar.warning("streamlit-webrtcãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'pip install streamlit-webrtc'ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    # ãƒ€ãƒŸãƒ¼é–¢æ•°ã‚’å®šç¾©ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ï¼‰
    def webrtc_streamer(*args, **kwargs):
        return None
    class WebRtcMode:
        SENDONLY = "sendonly"
    class RTCConfiguration:
        def __init__(self, *args, **kwargs):
            pass

import av
import scipy.io.wavfile

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'volume_history' not in st.session_state:
    st.session_state.volume_history = []  # éŸ³é‡å±¥æ­´
if 'last_sound_time' not in st.session_state:
    st.session_state.last_sound_time = time.time()  # æœ€å¾Œã«éŸ³ãŒæ¤œå‡ºã•ã‚ŒãŸæ™‚é–“
if 'current_drop_rate' not in st.session_state:
    st.session_state.current_drop_rate = 0  # ç¾åœ¨ã®éŸ³é‡ä½ä¸‹ç‡
if 'end_of_sentence_detected' not in st.session_state:
    st.session_state.end_of_sentence_detected = False  # æ–‡æœ«æ¤œå‡ºãƒ•ãƒ©ã‚°
if 'feedback_history' not in st.session_state:
    st.session_state.feedback_history = []  # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´
if 'page' not in st.session_state:
    st.session_state.page = "ãƒ›ãƒ¼ãƒ "  # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸
if 'ml_model' not in st.session_state:
    st.session_state.ml_model = VoiceQualityModel()  # éŸ³å£°å“è³ªãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False  # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´çŠ¶æ…‹


# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ‹¡å¼µ(ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ©Ÿèƒ½ç”¨)    
if 'recording' not in st.session_state:
    st.session_state.recording = False  # éŒ²éŸ³ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
if 'recorded_audio' not in st.session_state:
    st.session_state.recorded_audio = None  # éŒ²éŸ³æ¸ˆã¿éŸ³å£°ãƒ‡ãƒ¼ã‚¿
if 'temp_audio_file' not in st.session_state:
    st.session_state.temp_audio_file = None  # ä¸€æ™‚ä¿å­˜ç”¨ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
if 'is_capturing' not in st.session_state:
    st.session_state.is_capturing = False  # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
if 'capture_buffer' not in st.session_state:
    st.session_state.capture_buffer = None  # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ç”¨ãƒãƒƒãƒ•ã‚¡
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False  # éŸ³å£°åˆ†æå®Œäº†ãƒ•ãƒ©ã‚°
if 'last_analysis' not in st.session_state:
    st.session_state.last_analysis = None  # æœ€å¾Œã®åˆ†æçµæœ


# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
st.set_page_config(
    page_title="èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆã‚¢ãƒ—ãƒªã®UIï¼‰
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 5px;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #F5F5F5;
        padding: 1rem;
        border-radius: 5px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    .feedback-box {
            padding: 1rem;
            border-radius: 5px;
            margin-top: 1rem;
            margin-bottom: 1rem;
    }
    .feedback-good {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
    }
    .feedback-medium {
        background-color: #FFF8E1;
        border-left: 5px solid #FFC107;
    }
    .feedback-bad {
        background-color: #FFEBEE;
        border-left: 5px solid #F44336;
    }
</style>
""", unsafe_allow_html=True)

# ä¼šè©±ã‚µãƒ³ãƒ—ãƒ«
CONVERSATION_SAMPLES = {
    "å®¶æ—ã¨ã®ä¼šè©±": [
        "ä»Šæ—¥ã®å¤•é£Ÿã€ãƒ‘ã‚¹ã‚¿ã«ã™ã‚‹ã­",
        "ã•ã£ãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹ãŸï¼Ÿãªã‚“ã‹é¢ç™½ã‹ã£ãŸã­",
        "æ˜¼é–“ã«ã€åŠ è—¤ã•ã‚“ãŒæ¥ãŸ",
        "åœŸæ›œæ—¥ã¯ä½•ã‹äºˆå®šã‚ã‚‹ï¼Ÿ1æ™‚ã«é›†åˆã­"
    ],
    "å‹äººã¨ã®ä¼šè©±": [
        "ã“ã®é–“ã®è©±ã®ç¶šããªã‚“ã ã‘ã©ã€çµå±€ã©ã†ãªã£ãŸã®ï¼Ÿ",
        "æ‹æ‰‹ã—ãŸã‚‰ã€æœ€å¾Œã«æ¡æ‰‹ã—ã¦ãã‚ŒãŸã‚ˆ",
        "æ–°ã—ã„ã‚«ãƒ•ã‚§è¦‹ã¤ã‘ãŸã‚“ã ã€‚ä»Šåº¦ä¸€ç·’ã«è¡Œã‹ãªã„ï¼Ÿ",
        "æœ€è¿‘ã©ã†ï¼Ÿä½•ã‹å¤‰ã‚ã£ãŸã“ã¨ã‚ã£ãŸï¼Ÿ"
    ],
    "æ‹äººã¨ã®ä¼šè©±": [
        "ã¡ã‚‡ã£ã¨ã“ã‚Œæ‰‹ä¼ã£ã¦ã‚‚ã‚‰ãˆã‚‹ï¼Ÿã™ãçµ‚ã‚ã‚‹ã‹ã‚‰",
        "çª“é–‹ã‘ã¦ã‚‚ã‚‰ã£ã¦ã‚‚ã„ã„ï¼Ÿã¡ã‚‡ã£ã¨æš‘ã„ã¨æ€ã£ã¦",
        "ã‚¿ã‚¯ã‚·ãƒ¼å‘¼ã‚“ã ã‘ã©ã€å‚ã®ä¸Šã«æ­¢ã¾ã£ã¦ã‚‹",
        "ã‚ã®ã­ã€æ˜¨æ—¥è¦‹ãŸæ˜ ç”»ãŒã™ã”ãè‰¯ã‹ã£ãŸã‚“ã "
    ]
}

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¡¨ç¤º
def display_volume_meter(placeholder):
    if len(st.session_state.volume_history) > 0:
        df = pd.DataFrame(st.session_state.volume_history)
        df = df.reset_index().rename(columns={"index": "æ™‚é–“"})
        
        chart = alt.Chart(df).mark_line().encode(
            x=alt.X("æ™‚é–“", axis=None),
            y=alt.Y("éŸ³é‡", title="éŸ³é‡ (dB)", scale=alt.Scale(domain=[-80, 0]))
        ).properties(
            height=200,
            width='container'
        )
        
        placeholder.altair_chart(chart, use_container_width=True)

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã®è¡¨ç¤º
def display_feedback_history(placeholder):
    if len(st.session_state.feedback_history) > 0:
        placeholder.subheader("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´")
        
        for i, feedback in enumerate(reversed(st.session_state.feedback_history[-5:])):
            level = feedback["level"]
            css_class = f"feedback-box feedback-{level}"
            
            placeholder.markdown(
                f"<div class='{css_class}'>"
                f"<p>{feedback['time']} - {feedback['emoji']} {feedback['message']}</p>"
                f"<p>æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ç‡: {feedback['drop_rate']:.2f}</p>"
                f"</div>",
                unsafe_allow_html=True
            )

# éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ï¼ˆç°¡ç•¥ç‰ˆï¼‰
def audio_frame_callback(frame):
    """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    try:
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’numpyé…åˆ—ã«å¤‰æ›
        sound = frame.to_ndarray()
        
        # ç¾åœ¨ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        if len(sound) > 0:
            audio_data = sound.flatten()
            rms = np.sqrt(np.mean(audio_data**2))
            db = 20 * np.log10(max(rms, 1e-10))
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«éŸ³é‡å±¥æ­´ã‚’è¿½åŠ 
            st.session_state.volume_history.append({"éŸ³é‡": db})
            if len(st.session_state.volume_history) > 100:
                st.session_state.volume_history.pop(0)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
            silence_threshold = st.session_state.get('silence_threshold', -40)
            min_silence_duration = st.session_state.get('min_silence_duration', 500)
            
            # éŸ³é‡åˆ¤å®šã¨å‡¦ç†
            if db > silence_threshold:
                st.session_state.last_sound_time = time.time()
                st.session_state.end_of_sentence_detected = False
            else:
                # ç„¡éŸ³çŠ¶æ…‹ã®å‡¦ç†
                current_time = time.time()
                silence_duration = (current_time - st.session_state.last_sound_time) * 1000
                
                if silence_duration > min_silence_duration and not st.session_state.end_of_sentence_detected:
                    st.session_state.end_of_sentence_detected = True
                    
                    # æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ç‡ã‚’è¨ˆç®—
                    if len(st.session_state.volume_history) > 10:
                        recent_volumes = [item["éŸ³é‡"] for item in st.session_state.volume_history[-10:]]
                        
                        if len(recent_volumes) > 5:
                            before_avg = sum(recent_volumes[-7:-4]) / 3
                            after_avg = sum(recent_volumes[-3:]) / 3
                            drop_rate = (before_avg - after_avg) / (abs(before_avg) + 1e-10)
                            
                            st.session_state.current_drop_rate = drop_rate
                            
                            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã«è¿½åŠ 
                            feedback = get_feedback(drop_rate)
                            st.session_state.feedback_history.append({
                                "time": time.strftime("%H:%M:%S"),
                                "drop_rate": drop_rate,
                                "level": feedback["level"],
                                "message": feedback["message"],
                                "emoji": feedback["emoji"]
                            })
    
    except Exception as e:
        logger.error(f"éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    return frame

def main():
    # ç‰¹å¾´æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
    feature_extractor = VoiceFeatureExtractor()

    # ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
    st.title('èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼')
    st.write('èº«è¿‘ãªä¼šè©±ã‚’ã—ã£ã‹ã‚Šä¼ãˆã‚‹ã“ã¨ã§ã€å¤§åˆ‡ãªäººã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã‚ˆã†')

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸é¸æŠ", ["ãƒ›ãƒ¼ãƒ ", "ç·´ç¿’ã‚’å§‹ã‚ã‚‹", "ãƒ¢ãƒ‡ãƒ«è¨“ç·´"])
    st.session_state.page = page

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¨­å®šã‚’è¿½åŠ ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ©Ÿèƒ½ä½¿ç”¨æ™‚ã®ã¿ï¼‰
    if page == "ç·´ç¿’ã‚’å§‹ã‚ã‚‹" and WEBRTC_AVAILABLE:
        st.sidebar.title("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡è¨­å®š")
        st.session_state.silence_threshold = st.sidebar.slider(
            "ç„¡éŸ³ã—ãã„å€¤ (dB)", 
            -80, 0, -40,
            help="éŸ³å£°ã‚’ã€Œç„¡éŸ³ã€ã¨åˆ¤æ–­ã™ã‚‹éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚"
        )
        st.session_state.min_silence_duration = st.sidebar.slider(
            "æœ€å°ç„¡éŸ³æ™‚é–“ (ms)", 
            100, 500, 300,
            help="ã“ã®æ™‚é–“ä»¥ä¸Šã®ç„¡éŸ³ãŒç¶šã„ãŸå ´åˆã«ã€Œç„¡éŸ³åŒºé–“ã€ã¨åˆ¤æ–­ã—ã¾ã™ã€‚"
        )

    # ãƒšãƒ¼ã‚¸ã”ã¨ã®è¡¨ç¤ºå†…å®¹
    if page == "ãƒ›ãƒ¼ãƒ ":
        st.markdown('<h1 class="main-header">Welcomeï¼</h1>', unsafe_allow_html=True)
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.write("""
        ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®çŸ­ã„ä¼šè©±ã‚’åˆ†æã—ã€æ–‡æœ«ã®æ˜ç­ã•ã‚’é«˜ã‚ã‚‹ã“ã¨ã«æ³¨åŠ›ã—ã¦ã„ã¾ã™ã€‚
        æ—¥æœ¬èªã¯è¨€èªã®ç‰¹å¾´ä¸Šã€è‡ªç„¶ã¨èªå°¾ã®éŸ³å£°é‡ãŒä½ä¸‹ã—ãŒã¡ã§ã™ã€‚
        ã‚ãªãŸã®ç™ºè©±ã‚’åˆ†æã—ã¦ã€è©±ã—æ–¹ã‚’é«˜ã‚ã‚‹ãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
        """)
        st.markdown('</div>', unsafe_allow_html=True)

    elif page == "ç·´ç¿’ã‚’å§‹ã‚ã‚‹":
        st.markdown('<h1 class="sub-header">éŸ³å£°ç·´ç¿’</h1>', unsafe_allow_html=True)
    
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ã‚µãƒ³ãƒ—ãƒ«æ–‡ã®é¸æŠ
        category = st.selectbox("ä¼šè©±ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ", list(CONVERSATION_SAMPLES.keys()))
        sample_index = st.selectbox(
            "ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’é¸æŠ", 
            range(len(CONVERSATION_SAMPLES[category])),
            format_func=lambda i: CONVERSATION_SAMPLES[category][i]
        )
        
        selected_sample = CONVERSATION_SAMPLES[category][sample_index]
        
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.write("### èª­ã¿ä¸Šã’ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ–‡")
        st.write(selected_sample)
        st.write("ã“ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’ã€æ™®æ®µã®ã‚ˆã†ã«è‡ªç„¶ã«èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚")
        st.markdown('</div>', unsafe_allow_html=True)

        # ç·´ç¿’æ–¹æ³•ã®é¸æŠ
        if WEBRTC_AVAILABLE:
            practice_method = st.radio("ç·´ç¿’æ–¹æ³•ã‚’é¸æŠ", ["éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡"])
        else:
            practice_method = st.radio("ç·´ç¿’æ–¹æ³•ã‚’é¸æŠ", ["éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"])
            st.info("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€streamlit-webrtcã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")

        if practice_method == "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
            uploaded_file = st.file_uploader(
                "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", 
                type=["wav", "mp3"],
                key="file_uploader"
            )
            
            if uploaded_file is not None:
                tmp_file_path = None  # å¤‰æ•°ã‚’äº‹å‰ã«åˆæœŸåŒ–
                try:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_file_path = tmp_file.name

                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿå¯èƒ½ã«è¡¨ç¤º
                    st.audio(tmp_file_path, format='audio/wav')

                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                    y, sr = librosa.load(tmp_file_path, sr=None)

                    # éŸ³å£°ç‰¹å¾´é‡ã®æŠ½å‡º
                    features = feature_extractor.extract_features(y, sr)
                    
                    # éŸ³å£°åˆ†æã®è¦–è¦šåŒ–
                    st.subheader("éŸ³å£°åˆ†æçµæœ")
                    fig = plot_audio_analysis(features, y, sr)
                    st.pyplot(fig)
                    
                    # éŸ³é‡åˆ†æçµæœã®è¡¨ç¤º
                    st.markdown('<h2 class="sub-header">éŸ³é‡åˆ†æçµæœ</h2>', unsafe_allow_html=True)
                            
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        st.metric("å¹³å‡éŸ³é‡", f"{features['mean_volume']:.4f}")
                        st.metric("æ–‡é ­éŸ³é‡", f"{features['start_volume']:.4f}")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.metric("æ–‡ä¸­éŸ³é‡", f"{features['middle_volume']:.4f}")
                        st.metric("æ–‡æœ«éŸ³é‡", f"{features['end_volume']:.4f}")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡", f"{features['end_drop_rate']:.4f}")
                        st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡(æœ€å¾Œã®20%)", f"{features['last_20_percent_drop_rate']:.4f}")
                        st.markdown('</div>', unsafe_allow_html=True)

                    # éŸ³å£°æ˜ç­åº¦è©•ä¾¡
                    evaluation = evaluate_clarity(features)
                    
                    st.markdown('<h2 class="sub-header">éŸ³å£°æ˜ç­åº¦è©•ä¾¡</h2>', unsafe_allow_html=True)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        st.metric("æ˜ç­åº¦ã‚¹ã‚³ã‚¢", f"{evaluation['score']}/100")
                        st.metric("æ˜ç­åº¦è©•ä¾¡", evaluation['clarity_level'])
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                    with col2:
                        st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        st.write("ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                        st.write(evaluation['advice'])
                        st.markdown('</div>', unsafe_allow_html=True)

                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.unlink(tmp_file_path)

                except Exception as e:
                    st.error(f"éŸ³å£°åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
                    if tmp_file_path is not None and os.path.exists(tmp_file_path):
                        try:
                            os.unlink(tmp_file_path)
                        except Exception as e:
                            logger.error(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                            
        elif practice_method == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡" and WEBRTC_AVAILABLE:
            st.write("### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡")
            st.info("ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ãƒã‚¤ã‚¯ä½¿ç”¨è¨±å¯ã‚’æ‰¿èªã—ã¦ãã ã•ã„ã€‚")

            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®æº–å‚™
            status_placeholder = st.empty()
            volume_placeholder = st.empty()
            feedback_placeholder = st.empty()

            try:
                # WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’è¨­å®š
                webrtc_ctx = webrtc_streamer(
                    key="speech-evaluation",
                    mode=WebRtcMode.SENDONLY,
                    audio_frame_callback=audio_frame_callback,
                    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
                    media_stream_constraints={"video": False, "audio": True}
                )

                # WebRTCæ¥ç¶šãŒæœ‰åŠ¹ãªå ´åˆ
                if webrtc_ctx.state.playing:
                    # éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¡¨ç¤º
                    display_volume_meter(volume_placeholder)
                            
                    # çŠ¶æ…‹è¡¨ç¤º
                    if st.session_state.end_of_sentence_detected:
                        drop_rate = st.session_state.current_drop_rate
                                
                        if drop_rate < 0.1:
                            status_placeholder.success("è‰¯ã„æ„Ÿã˜ã§ã™ï¼èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºéŸ³ã§ãã¦ã„ã¾ã™ã€‚")
                        elif drop_rate < 0.25:
                            status_placeholder.info("èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚")
                        else:
                            status_placeholder.warning("èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’æ„è­˜ã—ã¦ï¼")
                    else:
                        status_placeholder.info("ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚")
                            
                    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã®è¡¨ç¤º
                    display_feedback_history(feedback_placeholder)
                else:
                    status_placeholder.warning("ãƒã‚¤ã‚¯æ¥ç¶šå¾…æ©Ÿä¸­...ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")

            except Exception as e:
                st.error(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ©Ÿèƒ½ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒšãƒ¼ã‚¸
    elif page == "ãƒ¢ãƒ‡ãƒ«è¨“ç·´":
        st.markdown('<h1 class="sub-header">ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡</h1>', unsafe_allow_html=True)
        
        st.write("""
        ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ»è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
        ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¾ã™ã€‚
        """)    
       
        if st.button("ãƒ¢ãƒ‡ãƒ«è¨“ç·´"):
            with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­..."):
                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
                X, y = generate_training_data()

                # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨è¨“ç·´
                if st.session_state.ml_model.train(X, y):
                    st.session_state.model_trained = True
                    st.success("ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")

                    # ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¡¨ç¤º
                    importance = st.session_state.ml_model.get_feature_importance()
                    if importance:
                        st.subheader("ç‰¹å¾´é‡ã®é‡è¦åº¦")
                        importance_df = pd.DataFrame(
                            list(importance.items()), 
                            columns=['ç‰¹å¾´é‡', 'é‡è¦åº¦']
                        ).sort_values('é‡è¦åº¦', ascending=False)
                        st.bar_chart(importance_df.set_index('ç‰¹å¾´é‡'))
                else:
                    st.error("ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«å¤±æ•—ã—ã¾ã—ãŸ")

# ã‚¢ãƒ—ãƒªã®å®Ÿè¡Œ
if __name__ == "__main__":
    main()  
