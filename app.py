import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import librosa
import librosa.display
import tempfile
import os # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¿…è¦
import queue
import altair as alt # ã‚°ãƒ©ãƒ•æç”»ç”¨ 
import time
import asyncio
import logging
from pydub import AudioSegment

#è¿½åŠ ã™ã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡
from ml_model import VoiceQualityModel, generate_training_data, create_dataset_from_files

# æ©Ÿæ¢°å­¦ç¿’é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸Šéƒ¨ï¼‰
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import joblib
    
# FFmpegè­¦å‘Šã®ç„¡è¦–è¨­å®šã‚’è¿½åŠ 
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning, message="Couldn't find ffmpeg or avconv")

# WebRTCé–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

try:
    from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration  # ãƒ–ãƒ©ã‚¦ã‚¶ã§éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
except ImportError:
    st.error("streamlit-webrtcãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'pip install streamlit-webrtc'ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    # ãƒ€ãƒŸãƒ¼é–¢æ•°ã‚’å®šç¾©ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ï¼‰
    def webrtc_streamer(*args, **kwargs):
        return None
    class WebRtcMode:
        SENDONLY = "sendonly"
    class RTCConfiguration:
        def __init__(self, *args, **kwargs):
            pass

import av
import scipy.io.wavfile
import logging

#ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)

# FFmpegè­¦å‘Šã®ç„¡è¦–è¨­å®šã‚’è¿½åŠ ï¼ˆã“ã“ã«è¿½åŠ ï¼‰
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning, message="Couldn't find ffmpeg or avconv")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'volume_history' not in st.session_state:
    st.session_state.volume_history = []  # éŸ³é‡å±¥æ­´
if 'last_sound_time' not in st.session_state:
    st.session_state.last_sound_time = time.time()  # æœ€å¾Œã«éŸ³ãŒæ¤œå‡ºã•ã‚ŒãŸæ™‚é–“
if 'current_drop_rate' not in st.session_state:
    st.session_state.current_drop_rate = 0  # ç¾åœ¨ã®éŸ³é‡ä½ä¸‹ç‡
if 'end_of_sentence_detected' not in st.session_state:
    st.session_state.end_of_sentence_detected = False  # æ–‡æœ«æ¤œå‡ºãƒ•ãƒ©ã‚°
if 'feedback_history' not in st.session_state:
    st.session_state.feedback_history = []  # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´
if 'page' not in st.session_state:
    st.session_state.page = "ãƒ›ãƒ¼ãƒ "  # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸

if 'ml_model' not in st.session_state:
    st.session_state.ml_model = VoiceQualityModel()  # éŸ³å£°å“è³ªãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False  # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´çŠ¶æ…‹


# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ‹¡å¼µ    
if 'recording' not in st.session_state:
    st.session_state.recording = False  # éŒ²éŸ³ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
if 'recorded_audio' not in st.session_state:
    st.session_state.recorded_audio = None  # éŒ²éŸ³æ¸ˆã¿éŸ³å£°ãƒ‡ãƒ¼ã‚¿
if 'temp_audio_file' not in st.session_state:
    st.session_state.temp_audio_file = None  # ä¸€æ™‚ä¿å­˜ç”¨ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
if 'is_capturing' not in st.session_state:
    st.session_state.is_capturing = False  # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
if 'capture_buffer' not in st.session_state:
    st.session_state.capture_buffer = None  # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ç”¨ãƒãƒƒãƒ•ã‚¡


# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
st.set_page_config(
    page_title="èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆã‚¢ãƒ—ãƒªã®è¦‹æ „ãˆã‚’ã‚ˆã‚Šã‚ˆã„ã‚‚ã®ã«ã™ã‚‹ãŸã‚ï¼‰
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 5px;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #F5F5F5;
        padding: 1rem;
        border-radius: 5px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    .feedback-box {
            padding: 1rem;
            border-radius: 5px;
            margin-top: 1rem;
            margin-bottom: 1rem;
    }
    .feedback-good {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
    }
    .feedback-medium {
        background-color: #FFF8E1;
        border-left: 5px solid #FFC107;
    }
    .feedback-bad {
        background-color: #FFEBEE;
        border-left: 5px solid #F44336;
    }
</style>
""", unsafe_allow_html=True)

# ä¼šè©±ã‚µãƒ³ãƒ—ãƒ«
CONVERSATION_SAMPLES = {
    "å®¶æ—ã¨ã®ä¼šè©±": [
        "ä»Šæ—¥ã®å¤•é£Ÿã€ãƒ‘ã‚¹ã‚¿ã«ã™ã‚‹ã­",
        "ã•ã£ãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹ãŸï¼Ÿãªã‚“ã‹é¢ç™½ã‹ã£ãŸã­",
        "æ˜¼é–“ã«ã€åŠ è—¤ã•ã‚“ãŒæ¥ãŸ",
        "åœŸæ›œæ—¥ã¯ä½•ã‹äºˆå®šã‚ã‚‹ï¼Ÿ1æ™‚ã«é›†åˆã­"
    ],
    "å‹äººã¨ã®ä¼šè©±": [
        "ã“ã®é–“ã®è©±ã®ç¶šããªã‚“ã ã‘ã©ã€çµå±€ã©ã†ãªã£ãŸã®ï¼Ÿ",
        "æ‹æ‰‹ã—ãŸã‚‰ã€æœ€å¾Œã«æ¡æ‰‹ã—ã¦ãã‚ŒãŸã‚ˆ",
        "æ–°ã—ã„ã‚«ãƒ•ã‚§è¦‹ã¤ã‘ãŸã‚“ã ã€‚ä»Šåº¦ä¸€ç·’ã«è¡Œã‹ãªã„ï¼Ÿ",
        "æœ€è¿‘ã©ã†ï¼Ÿä½•ã‹å¤‰ã‚ã£ãŸã“ã¨ã‚ã£ãŸï¼Ÿ"
    ],
    "æ‹äººã¨ã®ä¼šè©±": [
        "ã¡ã‚‡ã£ã¨ã“ã‚Œæ‰‹ä¼ã£ã¦ã‚‚ã‚‰ãˆã‚‹ï¼Ÿã™ãçµ‚ã‚ã‚‹ã‹ã‚‰",
        "çª“é–‹ã‘ã¦ã‚‚ã‚‰ã£ã¦ã‚‚ã„ã„ï¼Ÿã¡ã‚‡ã£ã¨æš‘ã„ã¨æ€ã£ã¦",
        "ã‚¿ã‚¯ã‚·ãƒ¼å‘¼ã‚“ã ã‘ã©ã€å‚ã®ä¸Šã«æ­¢ã¾ã£ã¦ã‚‹",
        "ã‚ã®ã­ã€æ˜¨æ—¥è¦‹ãŸæ˜ ç”»ãŒã™ã”ãè‰¯ã‹ã£ãŸã‚“ã "
    ]
}

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¡¨ç¤º
def display_volume_meter(placeholder):
    if len(st.session_state.volume_history) > 0:
        df = pd.DataFrame(st.session_state.volume_history)
        df = df.reset_index().rename(columns={"index": "æ™‚é–“"})
        
        chart = alt.Chart(df).mark_line().encode(
            x=alt.X("æ™‚é–“", axis=None),
            y=alt.Y("éŸ³é‡", title="éŸ³é‡ (dB)", scale=alt.Scale(domain=[-80, 0]))
        ).properties(
            height=200,
            width='container'
        )
        
        placeholder.altair_chart(chart, use_container_width=True)

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã®è¡¨ç¤º
def display_feedback_history(placeholder):
    if len(st.session_state.feedback_history) > 0:
        placeholder.subheader("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´")
        
        for i, feedback in enumerate(reversed(st.session_state.feedback_history[-5:])):  # æœ€æ–°5ä»¶ã®ã¿è¡¨ç¤º
            level = feedback["level"]
            css_class = f"feedback-box feedback-{level}"
            
            placeholder.markdown(
                f"<div class='{css_class}'>"
                f"<p>{feedback['time']} - {feedback['emoji']} {feedback['message']}</p>"
                f"<p>æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡: {feedback['drop_rate']:.2f}</p>"
                f"</div>",
                unsafe_allow_html=True
            )

# æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡ã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¿”ã™é–¢æ•°
def get_feedback(drop_rate):
    """
    drop_rateã«å¿œã˜ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆãƒ¬ãƒ™ãƒ«ãƒ»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ»çµµæ–‡å­—ï¼‰ã‚’è¿”ã™
    """
    if drop_rate < 0.1:
        return {
            "level": "good",
            "message": "è‰¯ã„æ„Ÿã˜ã§ã™ï¼èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºéŸ³ã§ãã¦ã„ã¾ã™ã€‚",
            "emoji": "âœ…"
        }
    elif drop_rate < 0.25:
        return {
            "level": "medium",
            "message": "èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚",
            "emoji": "ğŸŸ¡"
        }
    else:
        return {
            "level": "bad",
            "message": "èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’æ„è­˜ã—ã¦ï¼",
            "emoji": "âš ï¸"
        }

# éŒ²éŸ³é–‹å§‹/åœæ­¢ãƒœã‚¿ãƒ³
def toggle_recording():
    if st.session_state.recording:
        st.toast(f"**éŒ²éŸ³åœæ­¢**", icon="ğŸ¤")
    else:
        st.toast(f"**éŒ²éŸ³é–‹å§‹**", icon="ğŸ¤")
    st.session_state.recording = not st.session_state.recording
    if not st.session_state.recording:
        # éŒ²éŸ³åœæ­¢æ™‚ã€ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚‚åœæ­¢
        st.session_state.is_capturing = False

# éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°(éåŒæœŸå‡¦ç†å¯¾å¿œãƒãƒ¼ã‚¸ãƒ§ãƒ³)
def audio_frame_callback(frame):
    """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    try:
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’numpyé…åˆ—ã«å¤‰æ›
        sound = frame.to_ndarray()
        
        # ç¾åœ¨ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        if len(sound) > 0:
            audio_data = sound.flatten()
            rms = np.sqrt(np.mean(audio_data**2))
            db = 20 * np.log10(max(rms, 1e-10))
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«éŸ³é‡å±¥æ­´ã‚’è¿½åŠ 
            try:
                st.session_state.volume_history.append({"éŸ³é‡": db})
                if len(st.session_state.volume_history) > 100:
                    st.session_state.volume_history.pop(0)
            except Exception as volume_error:
                logger.error(f"éŸ³é‡å±¥æ­´ã®æ›´æ–°ã‚¨ãƒ©ãƒ¼: {volume_error}")
          
   
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è¨­å®šå¯èƒ½ï¼‰
            try:
                silence_threshold = st.session_state.get('silence_threshold', -40)  # ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ï¼ˆdBï¼‰
                min_silence_duration = st.session_state.get('min_silence_duration', 500)  # æœ€å°ç„¡éŸ³æ™‚é–“ï¼ˆmsï¼‰    
                       
                # éŸ³é‡åˆ¤å®šã¨å‡¦ç†ï¼ˆéŸ³é‡ãŒé–¾å€¤ã‚ˆã‚Šå¤§ãã„å ´åˆã€éŸ³å£°ã‚ã‚Šï¼‰
                if db > silence_threshold:
                    st.session_state.last_sound_time = time.time()
                    st.session_state.end_of_sentence_detected = False
                
                    # éŒ²éŸ³é–‹å§‹åˆ¤å®šï¼ˆéŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ãŒã‚ªãƒ³ã§ã€ã‹ã¤ã‚­ãƒ£ãƒ—ãƒãƒ£ãŒé–‹å§‹ã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
                    try:
                        if st.session_state.recording and not st.session_state.is_capturing:
                            st.session_state.is_capturing = True
                            if st.session_state.capture_buffer is None:
                                st.session_state.capture_buffer = AudioSegment.empty()
                    except Exception as rec_error:
                        logger.error(f"éŒ²éŸ³é–‹å§‹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {rec_error}")
                else:
                    # ç„¡éŸ³çŠ¶æ…‹ã®å‡¦ç†
                    try:
                        # ç„¡éŸ³çŠ¶æ…‹ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸå ´åˆã€æ–‡æœ«ã¨åˆ¤æ–­
                        current_time = time.time()
                        silence_duration = (current_time - st.session_state.last_sound_time) * 1000  # ãƒŸãƒªç§’ã«å¤‰æ›
                
                        if silence_duration > min_silence_duration and not st.session_state.end_of_sentence_detected:
                            st.session_state.end_of_sentence_detected = True                   
                         
                            # æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ç‡ã‚’è¨ˆç®—
                            if len(st.session_state.volume_history) > 10:
                                try:
                                    recent_volumes = [item["éŸ³é‡"] for item in st.session_state.volume_history[-10:]]
                        
                                    # ç°¡æ˜“çš„ãªæ–‡æœ«åˆ¤å®š
                                    if len(recent_volumes) > 5:
                                        before_avg = sum(recent_volumes[-7:-4]) / 3  # æ–‡æœ«å‰ã®å¹³å‡
                                        after_avg = sum(recent_volumes[-3:]) / 3    # æ–‡æœ«ã®å¹³å‡
                                        drop_rate = (before_avg - after_avg) / (abs(before_avg) + 1e-10)
                            
                                        # åˆ¤å®šçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                                        st.session_state.current_drop_rate = drop_rate
                            
                                        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã«è¿½åŠ 
                                        feedback = get_feedback(drop_rate)
                                        st.session_state.feedback_history.append({
                                            "time": time.strftime("%H:%M:%S"),
                                            "drop_rate": drop_rate,
                                            "level": feedback["level"],
                                            "message": feedback["message"],
                                            "emoji": feedback["emoji"]
                                        })
                                except Exception as fb_error:
                                    logger.error(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {fb_error}")

                        #ã€€éŒ²éŸ³åœæ­¢åˆ¤å®šï¼ˆéŒ²éŸ³ä¸­ã‹ã¤ç„¡éŸ³ãŒç¶šãå ´åˆï¼‰
                        auto_stop_duration = st.session_state.get('auto_stop_duration', 1000)
                        if st.session_state.recording and st.session_state.is_capturing and silence_duration > auto_stop_duration:
                            st.session_state.is_capturing = False
                            # ã“ã®æ™‚ç‚¹ã§éŒ²éŸ³ã‚’ä¿å­˜ã™ã‚‹å‡¦ç†ã‚’å‘¼ã³å‡ºã™ï¼ˆéåŒæœŸå‡¦ç†ã™ã‚‹ãŸã‚ã€ç›´æ¥å‘¼ã³å‡ºã•ãªã„ï¼‰

                        #ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¼å‡¦ç†           
                        try:
                            # ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¼ä¸­ã§ã‚ã‚Œã°éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                            if st.session_state.recording and st.session_state.is_capturing:
                                # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰pydubå½¢å¼ã«å¤‰æ›
                                audio_segment = AudioSegment(
                                    data=frame.to_ndarray().tobytes(),
                                    sample_width=frame.format.bytes,
                                    frame_rate=frame.sample_rate,
                                    channels=len(frame.layout.channels),
                                )
                                 
                                #ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                                if st.session_state.capture_buffer is None:
                                    st.session_state.capture_buffer = audio_segment
                                else:
                                    st.session_state.capture_buffer += audio_segment
                        except Exception as processing_error:
                            logger.error(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {processing_error}")
                    except Exception as e:
                        logger.error(f"éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            except Exception as param_error:
                logger.error(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {param_error}")
    except Exception as e:
        logger.error(f"éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)        

        return frame
            
              
        #ã€€éŒ²éŸ³åœæ­¢åˆ¤å®šï¼ˆéŒ²éŸ³ä¸­ã‹ã¤ç„¡éŸ³ãŒç¶šãå ´åˆï¼‰
        auto_stop_duration = st.session_state.get('auto_stop_duration', 1000)
        if st.session_state.recording and st.session_state.is_capturing and silence_duration > auto_stop_duration:
            st.session_state.is_capturing = False
            # ã“ã®æ™‚ç‚¹ã§éŒ²éŸ³ã‚’ä¿å­˜ã™ã‚‹å‡¦ç†ã‚’å‘¼ã³å‡ºã™ï¼ˆéåŒæœŸå‡¦ç†ã™ã‚‹ãŸã‚ã€ç›´æ¥å‘¼ã³å‡ºã•ãªã„ï¼‰
           
            try:
                # ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¼ä¸­ã§ã‚ã‚Œã°éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                if st.session_state.recording and st.session_state.is_capturing:
                # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰pydubå½¢å¼ã«å¤‰æ›
                    audio_segment = AudioSegment(
                        data=frame.to_ndarray().tobytes(),
                        sample_width=frame.format.bytes,
                        frame_rate=frame.sample_rate,
                        channels=len(frame.layout.channels),
                    )
            except Exception as capture_error:
                logger.error(f"éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼: {capture_error}")

                # ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                if st.session_state.capture_buffer is None:
                    st.session_state.capture_buffer = audio_segment
                else:
                    st.session_state.capture_buffer += audio_segment
    
    except Exception as e:
        logger.error (f"éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info = True)
    
    return frame

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ä¿å­˜ã¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã®è¡¨ç¤º (éåŒæœŸé–¢æ•°)
async def save_and_analyze_audio(audio_segment):
    if audio_segment is None or len(audio_segment) == 0:
        return
    
    # æœ€ä½éŒ²éŸ³æ™‚é–“ã®ãƒã‚§ãƒƒã‚¯
    min_recording_duration = st.session_state.get('min_recording_duration', 2)
    recording_duration = len(audio_segment) / 1000.0  # ãƒŸãƒªç§’ã‹ã‚‰ç§’ã«å¤‰æ›
    
    if recording_duration < min_recording_duration:
        return

 # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
        temp_file_path = tmp_file.name
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ (éåŒæœŸå‡¦ç†)
    await asyncio.to_thread(audio_segment.export, temp_file_path, format="wav")

    # ä»¥å‰ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
    if st.session_state.temp_audio_file and os.path.exists(st.session_state.temp_audio_file):
        try:
            os.unlink(st.session_state.temp_audio_file)
        except Exception as e:
            logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {e}")

    # æ–°ã—ã„ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ä¿å­˜
    st.session_state.temp_audio_file = temp_file_path
    st.session_state.recorded_audio = audio_segment
    
    # å‡¦ç†å¾Œã«ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
    st.session_state.capture_buffer = None
    
    # GCã‚’å¼·åˆ¶çš„ã«å®Ÿè¡Œã—ã¦ãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾
    import gc
    gc.collect()

    # éŸ³å£°åˆ†æã‚’è¡Œã†
    try:
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        y, sr = librosa.load(temp_file_path, sr=None)
        
        # ç‰¹å¾´é‡æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
        feature_extractor = VoiceFeatureExtractor()
        
        # éŸ³å£°ç‰¹å¾´é‡ã®æŠ½å‡º
        features = feature_extractor.extract_features(y, sr)
        
        # è©•ä¾¡çµæœã®ç”Ÿæˆ
        evaluation = evaluate_clarity(features)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜
        st.session_state.last_analysis = {
            "features": features,
            "evaluation": evaluation,
            "audio_path": temp_file_path,
            "audio_data": y,
            "sr": sr
        }
        
        # åˆ†æå®Œäº†ã®ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state.analysis_complete = True
 
    except Exception as e:
        logger.error(f"éŸ³å£°åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        st.session_state.analysis_error = str(e)

# éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def run_async(async_func, *args, **kwargs):
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(async_func(*args, **kwargs))
    finally:
        loop.close()


# VoiceFeatureExtractorã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¾ãŸã¯å®šç¾©
from ml_model import VoiceFeatureExtractor

# æ˜ç­åº¦è©•ä¾¡é–¢æ•°ã®å®šç¾©
def evaluate_clarity(features):
    """
    éŸ³å£°ç‰¹å¾´é‡ã‹ã‚‰æ˜ç­åº¦ã‚¹ã‚³ã‚¢ã¨è©•ä¾¡ã‚’è¿”ã™ç°¡æ˜“é–¢æ•°
    """
    # ä¾‹: æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡ã‚’ä¸»ãªæŒ‡æ¨™ã¨ã™ã‚‹
    drop_rate = features.get("end_drop_rate", 0.0)
    mean_volume = features.get("mean_volume", -40.0)
    score = max(0, 100 - int(drop_rate * 100) - int(abs(mean_volume + 20)))  # ä»®ã®ã‚¹ã‚³ã‚¢è¨ˆç®—

    if drop_rate < 0.1 and mean_volume > -30:
        clarity_level = "è‰¯å¥½"
        advice = "ç™ºè©±ã¯è‰¯å¥½ã§ã™ï¼æ–‡æœ«ã¾ã§æ˜ç­ã«è©±ã›ã¦ã„ã¾ã™ã€‚"
    elif drop_rate < 0.25:
        clarity_level = "æ™®é€š"
        advice = "æ–‡æœ«ãŒã‚„ã‚„å¼±ããªã£ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã¾ã§æ„è­˜ã—ã¦è©±ã—ã¾ã—ã‚‡ã†ã€‚"
    elif drop_rate < 0.4:
        clarity_level = "ã‚„ã‚„å¼±ã„"
        advice = "æ–‡æœ«ã®éŸ³é‡ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ¯ã‚’æ®‹ã—ã¦æœ€å¾Œã¾ã§è©±ã—ã¾ã—ã‚‡ã†ã€‚"
    else:
        clarity_level = "å¼±ã„"
        advice = "æ–‡æœ«ãŒã‹ãªã‚Šå¼±ããªã£ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’æ„è­˜ã—ã¦ç·´ç¿’ã—ã¾ã—ã‚‡ã†ã€‚"

    return {
        "score": score,
        "clarity_level": clarity_level,
        "advice": advice
    }

# ã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†
def main():
    # ç‰¹å¾´æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
    feature_extractor = VoiceFeatureExtractor()

     # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨è¨“ç·´
    if not st.session_state.model_trained:
        with st.spinner("æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­..."):
            try:
                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
                X, y = generate_training_data()
                
                # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
                if st.session_state.ml_model.train(X, y):
                    st.session_state.model_trained = True
                    st.toast("ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
    st.title('èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼')
    st.write('èº«è¿‘ãªä¼šè©±ã‚’ã—ã£ã‹ã‚Šä¼ãˆã‚‹ã“ã¨ã§ã€å¤§åˆ‡ãªäººã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã‚ˆã†')

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸é¸æŠ", ["ãƒ›ãƒ¼ãƒ ", "ç·´ç¿’ã‚’å§‹ã‚ã‚‹","ãƒ¢ãƒ‡ãƒ«è¨“ç·´", "æœ¬ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦"])
    st.session_state.page = page  # ãƒšãƒ¼ã‚¸çŠ¶æ…‹ã‚’æ›´æ–°

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç„¡éŸ³æ¤œå‡ºè¨­å®šã‚’è¿½åŠ 
    if page == "ç·´ç¿’ã‚’å§‹ã‚ã‚‹":
        st.sidebar.title("ç„¡éŸ³æ¤œå‡ºè¨­å®š")
        st.session_state.silence_threshold = st.sidebar.slider(
            "ç„¡éŸ³ã—ãã„å€¤ (dB)", 
            -80, 0, -40,
            help="éŸ³å£°ã‚’ã€Œç„¡éŸ³ã€ã¨åˆ¤æ–­ã™ã‚‹éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚\n"
                "å€¤ãŒå°ã•ã„ã»ã©ï¼ˆä¾‹ï¼š-50dBï¼‰ã‚ˆã‚Šå°ã•ãªéŸ³ã‚‚ã€ŒéŸ³å£°ã‚ã‚Šã€ã¨åˆ¤æ–­ã—ã¾ã™ã€‚\n"
                "å€¤ãŒå¤§ãã„ã»ã©ï¼ˆä¾‹ï¼š-20dBï¼‰å¤§ããªéŸ³ã®ã¿ã‚’ã€ŒéŸ³å£°ã‚ã‚Šã€ã¨åˆ¤æ–­ã—ã¾ã™ã€‚"
        )

        st.session_state.min_silence_duration = st.sidebar.slider(
            "æœ€å°ç„¡éŸ³æ™‚é–“ (ms)", 
            100, 500, 300,
            help="ã“ã®æ™‚é–“ä»¥ä¸Šã®ç„¡éŸ³ãŒç¶šã„ãŸå ´åˆã«ã€Œç„¡éŸ³åŒºé–“ã€ã¨åˆ¤æ–­ã—ã¾ã™ã€‚\n"
                "çŸ­ã™ãã‚‹ã¨è©±ã®é€”ä¸­ã®çŸ­ã„é–“ã‚‚ç„¡éŸ³ã¨åˆ¤æ–­ã•ã‚Œã€\n"
                "é•·ã™ãã‚‹ã¨é•·ã‚ã®é–“ã‚‚éŸ³å£°ã®ä¸€éƒ¨ã¨åˆ¤æ–­ã•ã‚Œã¾ã™ã€‚"
        )

        st.sidebar.title("éŒ²éŸ³è¨­å®š")
        st.session_state.auto_stop_duration = st.sidebar.slider(
            "ç„¡éŸ³æ¤œå‡ºæ™‚ã®è‡ªå‹•åœæ­¢ (ms)", 
            100, 2000, 1000,
            help="ã“ã®æ™‚é–“ä»¥ä¸Šã®ç„¡éŸ³ãŒç¶šãã¨ã€è‡ªå‹•çš„ã«éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã™ã€‚\n"
                "è©±è€…ã®ç™ºè©±ãŒçµ‚ã‚ã£ãŸã“ã¨ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®è¨­å®šã§ã™ã€‚\n"
                "çŸ­ã™ãã‚‹ã¨è©±ã®é€”ä¸­ã§éŒ²éŸ³ãŒæ­¢ã¾ã‚Šã€é•·ã™ãã‚‹ã¨ç„¡é§„ãªç„¡éŸ³æ™‚é–“ãŒéŒ²éŸ³ã•ã‚Œã¾ã™ã€‚"
        )
        
        st.session_state.min_recording_duration = st.sidebar.slider(
            "æœ€ä½éŒ²éŸ³æ™‚é–“ (ç§’)", 
            1, 10, 2,
            help="éŒ²éŸ³ã‚’ä¿å­˜ã™ã‚‹æœ€ä½é™ã®é•·ã•ã‚’è¨­å®šã—ã¾ã™ã€‚\n"
                "ã“ã‚Œã‚ˆã‚ŠçŸ­ã„éŒ²éŸ³ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚\n"
                "çŸ­ã™ãã‚‹ã¨é›‘éŸ³ãªã©ã‚‚éŒ²éŸ³ã•ã‚Œã‚„ã™ãã€é•·ã™ãã‚‹ã¨çŸ­ã„è¿”äº‹ãªã©ã‚‚ç„¡è¦–ã•ã‚Œã¾ã™ã€‚"
        )

    # ãƒšãƒ¼ã‚¸ã”ã¨ã®è¡¨ç¤ºå†…å®¹
    if page == "ãƒ›ãƒ¼ãƒ ":
        st.markdown('<h1 class="main-header">Welcomeï¼</h1>', unsafe_allow_html=True)
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.write("""
        ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®çŸ­ã„ä¼šè©±ã‚’åˆ†æã—ã€æ–‡æœ«ã®æ˜ç­ã•ã‚’é«˜ã‚ã‚‹ã“ã¨ã«æ³¨åŠ›ã—ã¦ã„ã¾ã™ã€‚
        æ—¥æœ¬èªã¯è¨€èªã®ç‰¹å¾´ä¸Šã€è‡ªç„¶ã¨èªå°¾ã®éŸ³å£°é‡ãŒä½ä¸‹ã—ãŒã¡ã§ã™ã€‚
        å®¶æ—ã‚„è¿‘ã—ã„äººã¨ã®ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªä¼šè©±ã‚„ã€å°å£°ã®ä¼šè©±ã§ç‰¹ã«ã“ã®å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚
        ä¸€æ–¹ã§æ„è­˜ã—ã™ãã¦å¤§ãã™ããŸã‚Šã€åŠ›ã‚’å…¥ã‚Œã™ãã‚‹ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãƒã‚¤ãƒŠã‚¹ã§ã™ã€‚
        ã‚ãªãŸã®ç™ºè©±ã‚’åˆ†æã—ã¦ã€è©±ã—æ–¹ã‚’é«˜ã‚ã‚‹ãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
        ãœã²ã€ã‚ãªãŸã®å£°ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚            
        
        ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ã‚ãªãŸã®ç™ºè©±ã‚’åˆ†æã—ã¦ã€èªå°¾ã®æ˜ç­ã•ã‚’è©•ä¾¡ã—ã€æ”¹å–„ã®ãŸã‚ã®ãƒ’ãƒ³ãƒˆã‚’
        æä¾›ã—ã¾ã™ã€‚2ã¤ã®æ–¹æ³•ã§ç·´ç¿’ã§ãã¾ã™ï¼š
        
        1. **éŒ²éŸ³æ¸ˆã¿ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**ã—ã¦è©³ç´°ãªåˆ†æã‚’å—ã‘ã‚‹
        2. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡**ã§ãƒã‚¤ã‚¯ã‹ã‚‰è©±ã—ãªãŒã‚‰å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾—ã‚‹
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
        st.markdown('<h2 class="sub-header">ä½¿ã„æ–¹</h2>', unsafe_allow_html=True)
        st.write("1. å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œç·´ç¿’ã‚’å§‹ã‚ã‚‹ã€ã‚’é¸æŠ")
        st.write("2. ç·´ç¿’ã—ãŸã„ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’é¸ã‚“ã§èª­ã¿ä¸Šã’ã‚‹")
        st.write("3. ã€ŒéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã¾ãŸã¯ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡ã€ã‚’é¸æŠ")
        st.write("4. åˆ†æçµæœã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç¢ºèª")
    
        if st.button("ç·´ç¿’ã‚’å§‹ã‚ã‚‹"):
            st.session_state.page = "ç·´ç¿’ã‚’å§‹ã‚ã‚‹"
            st.rerun() 

    elif page == "ç·´ç¿’ã‚’å§‹ã‚ã‚‹":
        st.markdown('<h1 class="sub-header">éŸ³å£°ç·´ç¿’</h1>', unsafe_allow_html=True)
    
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ã‚µãƒ³ãƒ—ãƒ«æ–‡ã®é¸æŠ
        category = st.selectbox("ä¼šè©±ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ", list(CONVERSATION_SAMPLES.keys()))
        sample_index = st.selectbox(
            "ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’é¸æŠ", 
            range(len(CONVERSATION_SAMPLES[category])),
            format_func=lambda i: CONVERSATION_SAMPLES[category][i]
        )
        
        selected_sample = CONVERSATION_SAMPLES[category][sample_index]
        
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.write("### èª­ã¿ä¸Šã’ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ–‡")
        st.write(selected_sample)
        st.write("ã“ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’ã€æ™®æ®µã®ã‚ˆã†ã«è‡ªç„¶ã«èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚")
        st.markdown('</div>', unsafe_allow_html=True)

        # ç·´ç¿’æ–¹æ³•ã®é¸æŠ
        practice_method = st.radio("ç·´ç¿’æ–¹æ³•ã‚’é¸æŠ", ["éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡"])

        if practice_method == "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ©Ÿèƒ½
            uploaded_file = st.file_uploader(
                "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", 
                type=["wav", "mp3"],
                key="file_uploader"
            )
            
            if uploaded_file is not None:
                try:
                    tmp_file_path = None  # åˆæœŸå€¤ã‚’è¨­å®š

                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    tmp_file_path = None               
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_file_path = tmp_file.name

                except Exception as e:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        st.stop()

                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
                audio_length = librosa.get_duration(path=tmp_file_path)

                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿå¯èƒ½ã«è¡¨ç¤º
                st.audio(tmp_file_path, format='audio/wav')

                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                y, sr = librosa.load(tmp_file_path, sr=None)

                # éŸ³å£°ç‰¹å¾´é‡ã®æŠ½å‡º
                features = feature_extractor.extract_features(y, sr)
                
                # éŸ³å£°åˆ†æã®è¦–è¦šåŒ–
                st.subheader("éŸ³å£°åˆ†æçµæœ")    

                # plot_audio_analysisé–¢æ•°ã®å®šç¾©
                def plot_audio_analysis(features, y, sr):
                    import matplotlib.pyplot as plt
                    import numpy as np

                    fig, ax = plt.subplots(2, 1, figsize=(10, 6), sharex=True)

                    # æ³¢å½¢ã®æç”»
                    times = np.arange(len(y)) / sr
                    ax[0].plot(times, y, color='b')
                    ax[0].set_title("éŸ³å£°æ³¢å½¢")
                    ax[0].set_ylabel("æŒ¯å¹…")
                    ax[0].grid(True)

                    # éŸ³é‡(RMS)ã®æç”»
                    if "rms" in features and "times" in features:
                        ax[1].plot(features["times"], features["rms"], color='g')
                        ax[1].set_title("éŸ³é‡ (RMS)")
                        ax[1].set_ylabel("RMS")
                        ax[1].set_xlabel("æ™‚é–“ (ç§’)")
                        ax[1].grid(True)
                    else:
                        ax[1].text(0.5, 0.5, "RMSãƒ‡ãƒ¼ã‚¿ãªã—", ha='center', va='center')

                    plt.tight_layout()
                    return fig

                fig = plot_audio_analysis(features, y, sr)
                st.pyplot(fig)
                
                # éŸ³é‡åˆ†æçµæœã®è¡¨ç¤º
                st.markdown('<h2 class="sub-header">éŸ³é‡åˆ†æçµæœ</h2>', unsafe_allow_html=True)
                        
                col1, col2, col3 = st.columns(3)
                with col1:
                    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®è¡¨ç¤º
                    st.markdown('<div class="info-box">', unsafe_allow_html=True)
                    st.metric("å¹³å‡éŸ³é‡", f"{features['mean_volume']:.4f}")
                    st.metric("æ–‡é ­éŸ³é‡", f"{features['start_volume']:.4f}")
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col2:
                    st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                    st.metric("æ–‡ä¸­éŸ³é‡", f"{features['middle_volume']:.4f}")
                    st.metric("æ–‡æœ«éŸ³é‡", f"{features['end_volume']:.4f}")
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col3:
                    st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                    st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡", f"{features['end_drop_rate']:.4f}")
                    st.metric("æ–‡æœ«éŸ³é‡ä½ä¸‹ç‡(æœ€å¾Œã®20%)", f"{features['last_20_percent_drop_rate']:.4f}")
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                # éŸ³å£°æ˜ç­åº¦è©•ä¾¡
                evaluation = evaluate_clarity(features)
                
                st.markdown('<h2 class="sub-header">éŸ³å£°æ˜ç­åº¦è©•ä¾¡</h2>', unsafe_allow_html=True)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown('<div class="info-box">', unsafe_allow_html=True)
                    st.metric("æ˜ç­åº¦ã‚¹ã‚³ã‚¢", f"{evaluation['score']}/100")
                    st.metric("æ˜ç­åº¦è©•ä¾¡", evaluation['clarity_level'])
                    st.metric("ã‚¹ã‚³ã‚¢", f"{evaluation['score']}ç‚¹")
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                with col2:
                    st.markdown('<div class="info-box">', unsafe_allow_html=True)
                    st.write("ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                    st.write(evaluation['advice'])
                    st.markdown('</div>', unsafe_allow_html=True)

                    # è©³ç´°ãªç‰¹å¾´é‡è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                    if st.checkbox("è©³ç´°ãªç‰¹å¾´é‡ã‚’è¡¨ç¤º"):
                        st.subheader("è©³ç´°ãªç‰¹å¾´é‡")
        
                    # ç‰¹å¾´é‡ã‚’ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«æ•´ç†ã—ã¦è¡¨ç¤º
                    # ãƒªã‚¹ãƒˆå‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã¾ãŸã¯å¤‰æ›
                    volume_features = {}
                    spectral_features = {}
                    rhythm_features = {}
        
                    # éŸ³é‡é–¢é€£ç‰¹å¾´é‡
                    for k, v in features.items():
                        if 'volume' in k or 'drop' in k:
                        # rmsã¨timesã¯é™¤å¤–ï¼ˆã“ã‚Œã‚‰ã¯ãƒªã‚¹ãƒˆå‹ã®ãŸã‚ï¼‰
                            if k not in ['rms', 'times'] and not isinstance(v, (list, np.ndarray)):
                                volume_features[k] = v
        
                    # ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡
                    for k, v in features.items():
                        if 'spectral' in k or 'mfcc' in k:
                            if not isinstance(v, (list, np.ndarray)):
                                spectral_features[k] = v
        
                    # ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡
                    for k, v in features.items():
                        if 'onset' in k or 'speech' in k:
                            if not isinstance(v, (list, np.ndarray)):
                                rhythm_features[k] = v
        
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ã¦è¡¨ç¤º
                    st.write("### éŸ³é‡é–¢é€£ç‰¹å¾´é‡")
                    if volume_features:
                        volume_df = pd.DataFrame({
                            'ç‰¹å¾´é‡': list(volume_features.keys()),
                            'å€¤': list(volume_features.values())
                        })
                        st.dataframe(volume_df)
                    else:
                        st.write("è¡¨ç¤ºã§ãã‚‹éŸ³é‡é–¢é€£ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
        
                    st.write("### ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡")
                    if spectral_features:
                        spectral_df = pd.DataFrame({
                            'ç‰¹å¾´é‡': list(spectral_features.keys()),
                            'å€¤': list(spectral_features.values())
                        })  
                        st.dataframe(spectral_df)
                    else:
                        st.write("è¡¨ç¤ºã§ãã‚‹ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
        
                    st.write("### ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡")
                    if rhythm_features:
                        rhythm_df = pd.DataFrame({
                            'ç‰¹å¾´é‡': list(rhythm_features.keys()),
                            'å€¤': list(rhythm_features.values())
                        })
                        st.dataframe(rhythm_df)
                    else:
                        st.write("è¡¨ç¤ºã§ãã‚‹ãƒªã‚ºãƒ é–¢é€£ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")

                         
                    # ç·´ç¿’ã®ãƒ’ãƒ³ãƒˆã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
                    st.markdown('<h2 class="sub-header">ç·´ç¿’ã®ãƒ’ãƒ³ãƒˆ</h2>', unsafe_allow_html=True)
                    st.markdown('<div class="info-box">', unsafe_allow_html=True)
                        
                    if evaluation["clarity_level"] in ["è‰¯å¥½"]:
                        st.write("è‰¯ã„èª¿å­ã§ã™ï¼èªå°¾ã¾ã§ç™ºè©±ã§ãã¦ã„ã¾ã™ã€‚")
                        st.write("- ã“ã®èª¿å­ã‚’ç¶­æŒã—ã¦ãã ã•ã„ï¼")
                        st.write("- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ä»–ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚„è‡ªç„¶ãªä¼šè©±ã§ã‚‚è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                    elif evaluation["clarity_level"] in ["æ™®é€š", "ã‚„ã‚„å¼±ã„"]:
                        st.write("- æ–‡ã®æœ€å¾Œã¾ã§æ¯ã‚’æ®‹ã™ã‚ˆã†ã«æ„è­˜ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                        st.write("- ä¾‹ãˆã°ã€æ–‡æœ«ã¾ã§æ„è­˜ã—ã¦è©±ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
                        st.write("- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: æ¯ã‚’å¸ã†ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ„è­˜ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                    else:
                        st.write("- æ–‡æœ«ã‚’æ„è­˜ã—ã¦ã€æ–‡ã‚’è©±ã—å§‹ã‚ã‚‹å‰ã«æ¯ã‚’å¸ã£ã¦ã‹ã‚‰è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                        st.write("- ä¾‹ãˆã°ã€æ–‡æœ«ã‚’1éŸ³ä¸Šã’ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                        st.write("- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: éŒ²éŸ³ã—ã¦ã”è‡ªèº«ã®å£°ã‚’è´ãã“ã¨ã§ã€è©±ã—æ–¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚")
                        
                    st.markdown('</div>', unsafe_allow_html=True)


            #æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬
            if st.session_state.model_trained and 'features' in locals():
                try:
                    prediction,confidence = st.session_state.ml_model.predict(features)
                    
                    st.markdown('<h2 class="sub-header">æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹éŸ³å£°å“è³ªäºˆæ¸¬</h2>', unsafe_allow_html=True)
                           
                    col1, col2 = st.columns(2)
                           
                    with col1:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.metric("éŸ³å£°å“è³ª", prediction)
                        st.metric("äºˆæ¸¬ä¿¡é ¼åº¦", f"{confidence:.2f}")
                        st.markdown('</div>', unsafe_allow_html=True)
                            
                    with col2:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.subheader("AIã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
            
                        if prediction == "è‰¯å¥½":
                            st.success("ç™ºè©±ã¯è‰¯å¥½ã§ã™ï¼æ–‡æœ«ã¾ã§æ˜ç­ã«è©±ã›ã¦ã„ã¾ã™ã€‚")
                            st.write("ã“ã®èª¿å­ã§ç¶šã‘ã¾ã—ã‚‡ã†ã€‚")
                        elif prediction == "æ–‡æœ«ãŒå¼±ã„":
                             st.warning("æ–‡æœ«ã®éŸ³é‡ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚")
                             st.write("æ—¥æœ¬èªã¯æ–‡æœ«ã«é‡è¦æƒ…å ±ãŒæ¥ã‚‹ã“ã¨ãŒå¤šã„ã®ã§ã€æ–‡æœ«ã¾ã§æ„è­˜ã—ã¦è©±ã™ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚")
                             st.write("- æ¯ã‚’æ·±ãå¸ã£ã¦ã‹ã‚‰è©±ã—å§‹ã‚ã‚‹")
                             st.write("- æ–‡ã®çµ‚ã‚ã‚Šã¾ã§ååˆ†ãªæ¯ã‚’æ®‹ã—ã¦ãŠã")
                             st.write("- æ–‡æœ«ã‚’å°‘ã—å¼·èª¿ã™ã‚‹æ„è­˜ã‚’æŒã¤")
                        elif prediction == "å°å£°ã™ãã‚‹":
                             st.warning("å…¨ä½“çš„ã«å£°ãŒå°ã•ã„ã§ã™ã€‚")
                             st.write("ç›¸æ‰‹ã«å±Šãã‚ˆã†ã€ã‚‚ã†å°‘ã—å£°é‡ã‚’ä¸Šã’ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚")
                             st.write("- å‘¼å¸ã‚’å°‘ã—ã ã‘æ„è­˜ã—ã¾ã—ã‚‡ã†")
                             st.write("- å°‘ã—å¤§ãã‚ã®å£°ã‚’å‡ºã™ç·´ç¿’ã‚’ã™ã‚‹")
                        st.markdown('</div>', unsafe_allow_html=True)
                            
                    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: éŒ²éŸ³ã—ã¦ã”è‡ªèº«ã®å£°ã‚’è´ãã“ã¨ã§ã€è©±ã—æ–¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚
                    st.write("- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: éŒ²éŸ³ã—ã¦ã”è‡ªèº«ã®å£°ã‚’è´ãã“ã¨ã§ã€è©±ã—æ–¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚")
                    st.markdown('</div>', unsafe_allow_html=True)    

                except Exception as e:
                    st.error(f"æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:    
                if not st.session_state.model_trained:
                    st.info("æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                elif 'features' not in locals():
                    st.info("éŸ³å£°ç‰¹å¾´é‡ãŒæŠ½å‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚éŸ³å£°ã‚’å†åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                    
                    # æœ€å¾Œã«ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰                   
                    if 'tmp_file_path' in locals() and os.path.exists(tmp_file_path):
                        try:
                            os.remove(tmp_file_path)
                        except Exception as e:
                            logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {e}") 
                       
            # ã‚¨ãƒ©ãƒ¼å‡¦ç†
            try:
                if 'e' in locals():
                    error_msg = str(e)

                    if "PySoundFile" in str(e):
                        st.error("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚åˆ¥ã®wavã¾ãŸã¯mp3å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
                    elif "empty_file" in str(e):
                        st.error("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒã„ã‚‹ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™ã€‚æœ‰åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                    else:
                        st.error(f"éŸ³å£°åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}")
            except Exception:
                st.error("éŸ³å£°åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

            try:
                 os.unlink(tmp_file_path)
            except:
                pass
                    

        elif practice_method == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡":
            st.write("### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡")
            st.info("ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ãƒã‚¤ã‚¯ä½¿ç”¨è¨±å¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ‰¿èªã—ã¦ãã ã•ã„ã€‚ãã®å¾Œã€ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’èª­ã¿ä¸Šã’ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è©•ä¾¡ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            use_fallback = st.checkbox("ãƒã‚¤ã‚¯æ¥ç¶šã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ãƒã‚§ãƒƒã‚¯", False)
    
            if use_fallback:
                st.warning("ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
                # ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ã§ã¯ä½•ã‚‚ã—ãªã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹
            
            else:
                # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®æº–å‚™ï¼ˆå‹•çš„æ›´æ–°ç”¨ï¼‰
                status_placeholder = st.empty()
                volume_placeholder = st.empty()
                feedback_placeholder = st.empty()
                history_placeholder = st.empty()
                recording_status_placeholder = st.empty()
                analysis_placeholder = st.empty()

                try:
                    # WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’è¨­å®š
                    webrtc_ctx = webrtc_streamer(
                        key="speech-evaluation",
                        mode=WebRtcMode.SENDONLY,
                        audio_frame_callback=audio_frame_callback,
                        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
                        media_stream_constraints={"video": False, "audio": True}
                    )
                except Exception as e:
                    st.error(f"WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                
                # WebRTCæ¥ç¶šãŒæœ‰åŠ¹ãªå ´åˆ
                if webrtc_ctx.state.playing:
                    # éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¡¨ç¤º
                    display_volume_meter(volume_placeholder)
                            
                    # çŠ¶æ…‹è¡¨ç¤º
                    if st.session_state.end_of_sentence_detected:
                        drop_rate = st.session_state.current_drop_rate
                                
                        if drop_rate < 0.1:
                            status_placeholder.success("- è‰¯ã„æ„Ÿã˜ã§ã™ï¼èªå°¾ã¾ã§ã—ã£ã‹ã‚Šç™ºéŸ³ã§ãã¦ã„ã¾ã™ã€‚")
                        elif drop_rate < 0.25:
                            status_placeholder.info("- èªå°¾ãŒã‚„ã‚„å¼±ã¾ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚")
                        else:
                            status_placeholder.warning("- èªå°¾ã®éŸ³é‡ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚æ–‡æœ«ã‚’æ„è­˜ã—ã¦ï¼")
                    else:
                        status_placeholder.info("- ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚æ–‡æœ«ã‚’æ¤œå‡ºã—ãŸã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                            
                    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã®è¡¨ç¤º
                    display_feedback_history(feedback_placeholder)

                    # ä½¿ã„æ–¹ã®è£œè¶³
                    with history_placeholder.expander("è©³ã—ã„ä½¿ã„æ–¹"):
                        st.write("""
                        1. ã‚µãƒ³ãƒ—ãƒ«æ–‡ã‚’è‡ªç„¶ãªå£°ã§èª­ã¿ä¸Šã’ã¦ãã ã•ã„
                        2. ä¸€åº¦ã«1ã¤ã®æ–‡ã‚’èª­ã¿ã€é–“ã‚’ç©ºã‘ã¾ã—ã‚‡ã†
                        3. æ–‡ã®çµ‚ã‚ã‚Šã§å°‘ã—é–“ã‚’ç©ºã‘ã‚‹ã¨ã€æ–‡æœ«ã¨åˆ¤æ–­ã•ã‚Œãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
                        4. è¤‡æ•°ã®æ–‡ã‚’èª­ã‚“ã§ç·´ç¿’ã‚’ç¶šã‘ã‚‹ã¨ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
                        5. éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§è‡ªåˆ†ã®å£°ã®å¤§ãã•ã‚’ç¢ºèªã§ãã¾ã™
                        """)
                                
                        st.write("### éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®ç›®å®‰")
                        st.write("- -20dBä»¥ä¸Š: å¤§ããªå£°")
                        st.write("- -30dBï½-20dB: é€šå¸¸ã®ä¼šè©±éŸ³é‡")
                        st.write("- -40dBï½-30dB: å°å£°")
                        st.write("- -40dBä»¥ä¸‹: éå¸¸ã«å°ã•ã„ã‹èã“ãˆãªã„éŸ³é‡")
                else:
                    status_placeholder.warning("ãƒã‚¤ã‚¯æ¥ç¶šå¾…æ©Ÿä¸­...ã€ŒSTARTã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")

            # éåŒæœŸå‡¦ç†: ã‚­ãƒ£ãƒ—ãƒãƒ£ãŒå®Œäº†ã—ãŸã‚‰éŸ³å£°ã‚’ä¿å­˜ãƒ»åˆ†æ
            
            try:
                if (st.session_state.get('capture_buffer') is not None and 
                    not st.session_state.is_capturing and 
                    st.session_state.end_of_sentence_detected):
                    # éåŒæœŸã§éŸ³å£°ã‚’ä¿å­˜ãƒ»åˆ†æ
                    run_async(save_and_analyze_audio, st.session_state.capture_buffer)
                    # ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.end_of_sentence_detected = False
          
            except Exception as e:
                st.error(f"ãƒã‚¤ã‚¯æ©Ÿèƒ½ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.info("ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ãŒWebRTCã«å¯¾å¿œã—ã¦ã„ãªã„ã‹ã€ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    elif page == "ãƒ¢ãƒ‡ãƒ«è¨“ç·´":
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒšãƒ¼ã‚¸ã®å†…å®¹
        st.markdown('<h1 class="sub-header">ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡</h1>', unsafe_allow_html=True)
        
        st.write("""
        ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ»è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
        ä»¥ä¸‹ã®æ–¹æ³•ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã§ãã¾ã™ï¼š
        1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´(ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿)
        """)    
       
        if st.button("ãƒ¢ãƒ‡ãƒ«è¨“ç·´"):
            with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­..."):
                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
                X, y = generate_training_data()

                # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨è¨“ç·´
                model = VoiceQualityModel()
                model.train(X, y)
                
                # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
                st.session_state.ml_model = model
                st.session_state.model_trained = True

                st.success("ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")
            


    elif page == "æœ¬ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦":
        st.markdown('<h1 class="sub-header">ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦</h1>', unsafe_allow_html=True)
            
        st.write("""
        ## èªå°¾ã¾ã§ã—ã£ã‹ã‚Šãƒã‚¹ã‚¿ãƒ¼
            
        ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸéŸ³å£°åˆ†æã‚¢ãƒ—ãƒªã§ã™ã€‚ç‰¹ã«æ—¥æœ¬èªã®æ–‡æœ«ã®éŸ³é‡ä½ä¸‹ã®å‚¾å‘ã‚’æ¤œå‡ºã—ã€ã‚ˆã‚Šæ˜ç¢ºãªç™ºè©±ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
            
        ### é–‹ç™ºèƒŒæ™¯
            
        æ—¥æœ¬èªã¯SOVå‹ã®è¨€èªã§ã‚ã‚Šã€æ–‡æœ«ã«è¿°èªã‚„é‡è¦ãªæƒ…å ±ãŒé›†ä¸­ã—ã¾ã™ã€‚ã—ã‹ã—ç™ºè©±ä¸­ã¯æ™‚é–“ã®çµŒéã¨ã¨ã‚‚ã«è‚ºã®ç©ºæ°—ãŒæ¸›å°‘ã—ã€æ–‡æœ«ã§ã¯è‡ªç„¶ã¨å£°é‡ãŒä½ä¸‹ã—ã¾ã™ã€‚ç‰¹ã«å®¶æ—ã‚„å‹äººã¨ã®è¦ªå¯†ãªä¼šè©±ã§ã¯æ°—ãŒç·©ã¿ã€ã“ã®å‚¾å‘ãŒå¼·ããªã‚Šã¾ã™ã€‚
            
               
        ### æ—¥æœ¬èªã®SOVæ§‹é€ ã¨éŸ³é‡ä½ä¸‹
            
        æ—¥æœ¬èªã®ã‚ˆã†ãªSOVæ§‹é€ ï¼ˆSubject-Object-Verbã€ä¸»èª-ç›®çš„èª-å‹•è©ï¼‰ã®è¨€èªã§ã¯ã€æ–‡æœ«ã«å‹•è©ã‚„é‡è¦ãªæƒ…å ±ãŒæ¥ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ä¾‹ãˆã°ï¼š
            
        - ã€Œç§ã¯**ãƒªãƒ³ã‚´ã‚’é£Ÿã¹ã¾ã™**ã€ï¼ˆæ—¥æœ¬èªï¼šSOVï¼‰
        - "I eat an apple"ï¼ˆè‹±èªï¼šSVOï¼‰
            
        è‹±èªã§ã¯ç›®çš„èªï¼ˆappleï¼‰ãŒæ–‡æœ«ã«ã‚ã‚Šã¾ã™ãŒã€æ—¥æœ¬èªã§ã¯å‹•è©ï¼ˆé£Ÿã¹ã¾ã™ï¼‰ãŒæ–‡æœ«ã«æ¥ã¾ã™ã€‚ã“ã®ãŸã‚ã€æ—¥æœ¬èªã§ã¯æ–‡æœ«ã®æ˜ç­ã•ãŒã‚ˆã‚Šé‡è¦ã«ãªã‚Šã¾ã™ã€‚
            
        ### ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½
            
        - éŸ³å£°æ³¢å½¢ã¨éŸ³é‡å¤‰åŒ–ã®å¯è¦–åŒ–
        - æ–‡æœ«éŸ³é‡ä½ä¸‹ã®æ¤œå‡ºã¨è©•ä¾¡
        - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®æä¾›
        - è©³ç´°ãªéŸ³å£°ç‰¹å¾´é‡ã®åˆ†æ
        - ç·´ç¿’ã®ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«æ–‡ã®æä¾›
            
        ### ä½¿ç”¨æŠ€è¡“
            
        - Python
        - Streamlit
        - librosaï¼ˆéŸ³å£°å‡¦ç†ï¼‰
        - WebRTCï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ï¼‰
        - æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆç‰¹å¾´é‡åˆ†æï¼‰
            
        ### å‚è€ƒæ–‡çŒ®
            
        - Chasin M. Sentence final hearing aid gain requirements of some non-English languages. Can J Speech-Lang Pathol Audiol. 2012;36(3):196-203.
        - æ—¥æœ¬èªæ—¥å¸¸ä¼šè©±ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰è¦‹ãˆã‚‹ä¼šè©±å ´é¢ã¨å£°ã®é«˜ã•ã®é–¢ä¿‚æ€§ (https://repository.ninjal.ac.jp/records/3193)
        - å°å£°ã¨ã¯ä½•ã‹ã€ã¾ãŸã¯è¨€èªã®é•ã„ãŒå°å£°ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã®ã‹ (https://www.oticon.co.jp/hearing-aid-users/blog/2020/20200512)
        """)
            
        st.write("### ç•™æ„äº‹é …")
        st.info("""
        - æœ¬ã‚¢ãƒ—ãƒªã¯ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ãŸã‚ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é…æ…®ã—ã¦ãã ã•ã„
        - éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ã«ä¿å­˜ã•ã‚Œã€åˆ†æå¾Œã«å‰Šé™¤ã•ã‚Œã¾ã™
        - æœ¬ã‚¢ãƒ—ãƒªã¯ã€ä¸€èˆ¬çš„ãªéŸ³å£°åˆ†æã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€ç‰¹å®šã®å€‹äººã‚„çŠ¶æ³ã«å¯¾ã™ã‚‹è©•ä¾¡ã‚’è¡Œã†ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“
        - æœ¬ã‚¢ãƒ—ãƒªã¯ã€å°‚é–€çš„ãªéŸ³å£°åˆ†æãƒ„ãƒ¼ãƒ«ã§ã¯ãªãã€ã‚ãã¾ã§å‚è€ƒã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„
        """)

# ã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã™ã‚‹å‰ã«ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
def cleanup():
    if st.session_state.get('temp_audio_file') and os.path.exists(st.session_state.temp_audio_file):
        try:
            os.unlink(st.session_state.temp_audio_file)
        except Exception as e:
            logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {e}")

# ã‚¢ãƒ—ãƒªã®å®Ÿè¡Œ
if __name__ == "__main__":
    try:
        main()
    finally:
        cleanup()
